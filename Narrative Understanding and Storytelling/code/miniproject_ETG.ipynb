{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["yF6KO5td8rFE","ToWlN7pdw6aG","Dm_IIhDqcOH3","UrScRUmhrAxZ","YKZUWBUBK0C5","7vjFj900Ki-h","7d6dRCN2qWPL","YbgwX4glw_EH","99kJ2CuVdtHA","hqXYjtOnhB16","qM6EXVubhB16","qduTsgmchB17","xNPxa9TXdwYy","WU5KEK_VZ3a2","qyjy16yqZ5nz","GDlQUDEZgVJo","CmaSO4dIh3NK","tJwMIeajMQWO","86HyuZFwW2Gf","aND-ojt7sXPT","5vTI0Fy6NsOX"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6d60430491c64b19b99b3dd92347f7c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9572d032cfa345ea86cc9a8881e81cef","IPY_MODEL_e06a2711579f4c8aab89400c0395c109","IPY_MODEL_7f3aa6d94a0a493f8a93ac457f3d6c75"],"layout":"IPY_MODEL_5fea08a2068a438f8c3c1e8022f7209c"}},"9572d032cfa345ea86cc9a8881e81cef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3adce8ab9a54a5e9abecf8c690a82d1","placeholder":"​","style":"IPY_MODEL_b1b572269e174f0f978a97d9d8df31eb","value":"Downloading (…)lve/main/config.json: 100%"}},"e06a2711579f4c8aab89400c0395c109":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a74222607dbd4d3484552f5c398473a3","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_480517d999e246b8b0b4d3c2640c0268","value":1208}},"7f3aa6d94a0a493f8a93ac457f3d6c75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa9f17ef89dd4eea8a3da92b5b0af968","placeholder":"​","style":"IPY_MODEL_6cca392a7ab54dcaa5beb42f0b7d34e5","value":" 1.21k/1.21k [00:00&lt;00:00, 24.3kB/s]"}},"5fea08a2068a438f8c3c1e8022f7209c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3adce8ab9a54a5e9abecf8c690a82d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b572269e174f0f978a97d9d8df31eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a74222607dbd4d3484552f5c398473a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"480517d999e246b8b0b4d3c2640c0268":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa9f17ef89dd4eea8a3da92b5b0af968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cca392a7ab54dcaa5beb42f0b7d34e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1738571c93e24286ae48aa3c3f48630c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f46fd6f31abf4b5eba3a961482dc506a","IPY_MODEL_bfc4c568bfcf4a668bbaced654eca4ee","IPY_MODEL_c974be9bff6b4c0f820fadb5bd03b5e8"],"layout":"IPY_MODEL_fea8b4262a4f45698e96cfb3554bde32"}},"f46fd6f31abf4b5eba3a961482dc506a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e5c4c871624477ca169c438d6d67452","placeholder":"​","style":"IPY_MODEL_94e7b86cd8b9457d90360d5fd1da5fe6","value":"Downloading (…)ve/main/spiece.model: 100%"}},"bfc4c568bfcf4a668bbaced654eca4ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b13e6b19451440cb5fe55eb06a570b6","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8198025e89c48aab679bfa5af101f4b","value":791656}},"c974be9bff6b4c0f820fadb5bd03b5e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af154c0522b843d89bf1d8b400457438","placeholder":"​","style":"IPY_MODEL_f047ba88e3234e699c6da8b027ab458a","value":" 792k/792k [00:00&lt;00:00, 11.4MB/s]"}},"fea8b4262a4f45698e96cfb3554bde32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e5c4c871624477ca169c438d6d67452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94e7b86cd8b9457d90360d5fd1da5fe6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b13e6b19451440cb5fe55eb06a570b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8198025e89c48aab679bfa5af101f4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af154c0522b843d89bf1d8b400457438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f047ba88e3234e699c6da8b027ab458a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"973680bb4dcc4c7dbbd6aa88d2edbe42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a43e081fd524469a66d61458edb936f","IPY_MODEL_735869d94acb48bcb36aa6142fef12d8","IPY_MODEL_3e034e8c37634b0f9968f62aa6ee678d"],"layout":"IPY_MODEL_6a50355240364fc29a415b0d679a00da"}},"7a43e081fd524469a66d61458edb936f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c0cb98311594fb19a4ed12dddbb04ef","placeholder":"​","style":"IPY_MODEL_ed0a5f5556424f7bba182e1145a04660","value":"Downloading (…)/main/tokenizer.json: 100%"}},"735869d94acb48bcb36aa6142fef12d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a9840173b754511b3060d29dff784be","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3ecc0055f2b407a9a0ba2bd257293eb","value":1389353}},"3e034e8c37634b0f9968f62aa6ee678d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a35fa31a33348a2bdf3a3a2e72ab4a5","placeholder":"​","style":"IPY_MODEL_f7b7d3e13e4841309c3afcf3d67a87b3","value":" 1.39M/1.39M [00:00&lt;00:00, 6.44MB/s]"}},"6a50355240364fc29a415b0d679a00da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c0cb98311594fb19a4ed12dddbb04ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed0a5f5556424f7bba182e1145a04660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a9840173b754511b3060d29dff784be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3ecc0055f2b407a9a0ba2bd257293eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a35fa31a33348a2bdf3a3a2e72ab4a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7b7d3e13e4841309c3afcf3d67a87b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc95ee02a98b40f0af5547c4976db112":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9eb9684d1ed4f8e84a746426f435e93","IPY_MODEL_3143ee3d78d34b2d97389c2ab09ff44c","IPY_MODEL_35346576b6fd4efaa64d8056a5937e39"],"layout":"IPY_MODEL_e65d4419eede490e8ae1a53419cdaab2"}},"f9eb9684d1ed4f8e84a746426f435e93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1288360ecba5460a8e702f7bd5d9c4da","placeholder":"​","style":"IPY_MODEL_1618f5b1f43645afb00a1a837257b6cf","value":"Downloading (…)olve/main/vocab.json: 100%"}},"3143ee3d78d34b2d97389c2ab09ff44c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cff75ea575d14f0fb51549bac0701811","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3a849165fd04eb4836e37e919d85abb","value":1042301}},"35346576b6fd4efaa64d8056a5937e39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3fe7a38847e47da8da8a228c21fd05a","placeholder":"​","style":"IPY_MODEL_2b866fd72aea4354b5b831d2eeb44773","value":" 1.04M/1.04M [00:00&lt;00:00, 25.2MB/s]"}},"e65d4419eede490e8ae1a53419cdaab2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1288360ecba5460a8e702f7bd5d9c4da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1618f5b1f43645afb00a1a837257b6cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cff75ea575d14f0fb51549bac0701811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a849165fd04eb4836e37e919d85abb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3fe7a38847e47da8da8a228c21fd05a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b866fd72aea4354b5b831d2eeb44773":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42dae7f3cc554461a2da97ebb71ae095":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ec8f2d1c0ae431ab6b3445459916ec1","IPY_MODEL_0f02df2a969545a3a020deec76bca219","IPY_MODEL_22820aa70c4a43b8b7093e1d6fc088c7"],"layout":"IPY_MODEL_34975aba931d47d18fda98c62b35a6ac"}},"5ec8f2d1c0ae431ab6b3445459916ec1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55945eceecd3424da09d6fea0f4b7765","placeholder":"​","style":"IPY_MODEL_f5f8c7fc5ec34339be3650bc07918586","value":"Downloading (…)olve/main/merges.txt: 100%"}},"0f02df2a969545a3a020deec76bca219":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_534af7fc78564b4bb151ddd87926b323","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cb9e49aaadb49dc887e64c83adaa388","value":456318}},"22820aa70c4a43b8b7093e1d6fc088c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc82c3272fa8465982ab7d8f70ec11d9","placeholder":"​","style":"IPY_MODEL_47a07345e0814445b7c205532c2f2e19","value":" 456k/456k [00:00&lt;00:00, 23.8MB/s]"}},"34975aba931d47d18fda98c62b35a6ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55945eceecd3424da09d6fea0f4b7765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5f8c7fc5ec34339be3650bc07918586":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"534af7fc78564b4bb151ddd87926b323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cb9e49aaadb49dc887e64c83adaa388":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc82c3272fa8465982ab7d8f70ec11d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47a07345e0814445b7c205532c2f2e19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2df8243c9139477587865ebf7b082555":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8104da9a1d5447208df1ac82161092f5","IPY_MODEL_c5e7163e1c1849f88accf8ea4f368113","IPY_MODEL_6ed405186a6747c3ac4240ec6d071686"],"layout":"IPY_MODEL_d52e29c372434228b9f4842778b1e8cb"}},"8104da9a1d5447208df1ac82161092f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_173cb086bb7b4f5d9c91eb88eec4e9c8","placeholder":"​","style":"IPY_MODEL_c5a8f6c010c24f6c9b68036183e56bd4","value":"Downloading (…)lve/main/config.json: 100%"}},"c5e7163e1c1849f88accf8ea4f368113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2058a629eec3405ba4112085d4f93c3d","max":762,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad95a3586c5945ab83101972ebbb9340","value":762}},"6ed405186a6747c3ac4240ec6d071686":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c278ed39e18845d4bd309cd138765163","placeholder":"​","style":"IPY_MODEL_4c2b19f3b0b44a1385936f5655f0810b","value":" 762/762 [00:00&lt;00:00, 61.9kB/s]"}},"d52e29c372434228b9f4842778b1e8cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"173cb086bb7b4f5d9c91eb88eec4e9c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a8f6c010c24f6c9b68036183e56bd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2058a629eec3405ba4112085d4f93c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad95a3586c5945ab83101972ebbb9340":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c278ed39e18845d4bd309cd138765163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c2b19f3b0b44a1385936f5655f0810b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a3038acd7d342de8afeba8026bd0a62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7c3a5b2f88f4306add385c481ae294a","IPY_MODEL_0c0db7f6bbd8405ea4497f3ddc49b85c","IPY_MODEL_f0b62a538f7c48feb0c83b722fc57813"],"layout":"IPY_MODEL_3b1e5c8837e542249d4c5b6307f34456"}},"d7c3a5b2f88f4306add385c481ae294a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22b1f43c02214f9e9b5a209dd0ec3709","placeholder":"​","style":"IPY_MODEL_c953f417d5b244489cf34d8a8ab5b79d","value":"Downloading model.safetensors: 100%"}},"0c0db7f6bbd8405ea4497f3ddc49b85c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d576e004e0c416c9e0cc5ace5d1f0fd","max":352824413,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c96d963cccc741c3bb88c75c54443d25","value":352824413}},"f0b62a538f7c48feb0c83b722fc57813":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecb2a9fe4e5149a982d621bdf33749b7","placeholder":"​","style":"IPY_MODEL_e4f867f683b54c3d858493db6c3b116c","value":" 353M/353M [00:03&lt;00:00, 169MB/s]"}},"3b1e5c8837e542249d4c5b6307f34456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22b1f43c02214f9e9b5a209dd0ec3709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c953f417d5b244489cf34d8a8ab5b79d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d576e004e0c416c9e0cc5ace5d1f0fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96d963cccc741c3bb88c75c54443d25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecb2a9fe4e5149a982d621bdf33749b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f867f683b54c3d858493db6c3b116c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3fcafa024d6401887e6884a770d0722":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_866ab6d705fd49009572ba59c6be4964","IPY_MODEL_6340aece0ca542d78acc862e41f47333","IPY_MODEL_d661208e84784f3794b1bcff554bf5ca"],"layout":"IPY_MODEL_2a4ff7c6b4cb42039fd9b3251610f094"}},"866ab6d705fd49009572ba59c6be4964":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0683182380248838214a31899e684d2","placeholder":"​","style":"IPY_MODEL_c822fb67fb88480089d7e9f655209f2a","value":"Downloading (…)neration_config.json: 100%"}},"6340aece0ca542d78acc862e41f47333":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbfbb665cd0c43f6a2d096cc4e363efb","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52a9d88e327d4f7f994d1d7d7f8efebf","value":124}},"d661208e84784f3794b1bcff554bf5ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edab427abe7a419ca6003c1ae9246aac","placeholder":"​","style":"IPY_MODEL_04e582e6b8f948dd968ec89417216bc6","value":" 124/124 [00:00&lt;00:00, 9.39kB/s]"}},"2a4ff7c6b4cb42039fd9b3251610f094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0683182380248838214a31899e684d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c822fb67fb88480089d7e9f655209f2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbfbb665cd0c43f6a2d096cc4e363efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52a9d88e327d4f7f994d1d7d7f8efebf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edab427abe7a419ca6003c1ae9246aac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e582e6b8f948dd968ec89417216bc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c33608d08d44e79b94a9d0c0b6d2f36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28c24f9873ff4756a3d8e38250a3089f","IPY_MODEL_4b916b5f5eb743f09b236f8d831b97e7","IPY_MODEL_3789d49d18bd47f7afdacae15e7d00e9"],"layout":"IPY_MODEL_501abc81079d4ba88842686e397e8b48"}},"28c24f9873ff4756a3d8e38250a3089f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_874da387dc2a446785c8a14feae33cda","placeholder":"​","style":"IPY_MODEL_a6f364d2ed164b6eafe0b3d750716aab","value":"Downloading model.safetensors: 100%"}},"4b916b5f5eb743f09b236f8d831b97e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c163d77b650348d49e8411c61ebd7c63","max":891646390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95c3137708764db4802bf8e881f9ae7b","value":891646390}},"3789d49d18bd47f7afdacae15e7d00e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ce8554c21c5492ca01a1aa2860d2356","placeholder":"​","style":"IPY_MODEL_1482e2d7bedf407eb21688947150b855","value":" 892M/892M [00:03&lt;00:00, 253MB/s]"}},"501abc81079d4ba88842686e397e8b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"874da387dc2a446785c8a14feae33cda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f364d2ed164b6eafe0b3d750716aab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c163d77b650348d49e8411c61ebd7c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95c3137708764db4802bf8e881f9ae7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ce8554c21c5492ca01a1aa2860d2356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1482e2d7bedf407eb21688947150b855":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e50ca31a464467082ce1f04bcaeaeb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a2e9bb9f5784c4bac6c4796ae566b58","IPY_MODEL_73da7c6fcf7d42c7a121fd9a3e5dd8f7","IPY_MODEL_e2cba565bf8c41b58a205520329dbd94"],"layout":"IPY_MODEL_5b88f2b0975d42cf9056a74f87722768"}},"2a2e9bb9f5784c4bac6c4796ae566b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_673e0d274532479aaf78f88a7dcc67ea","placeholder":"​","style":"IPY_MODEL_7a2219e9d1d14826afb8b9f384e42a3a","value":"Downloading (…)neration_config.json: 100%"}},"73da7c6fcf7d42c7a121fd9a3e5dd8f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d6bbe9e9c4642b1a1330c548ab407fb","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98260da3938e45e39788a07ab7c24607","value":147}},"e2cba565bf8c41b58a205520329dbd94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_583ef3851588465d9f5828f4268fd51d","placeholder":"​","style":"IPY_MODEL_dada19947a9145ebabd2635bf1388c2e","value":" 147/147 [00:00&lt;00:00, 8.66kB/s]"}},"5b88f2b0975d42cf9056a74f87722768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"673e0d274532479aaf78f88a7dcc67ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a2219e9d1d14826afb8b9f384e42a3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d6bbe9e9c4642b1a1330c548ab407fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98260da3938e45e39788a07ab7c24607":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"583ef3851588465d9f5828f4268fd51d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dada19947a9145ebabd2635bf1388c2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4939cf24a6142f6a5944ad1de54b987":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60b3557649cf44d292142aac5285d97f","IPY_MODEL_cd581bd64e4646e6b7e4ad68c640d24e","IPY_MODEL_1e927639569b41ad890b8b91ced4fc13"],"layout":"IPY_MODEL_b378a4f36d7a47b29dae226be34a894e"}},"60b3557649cf44d292142aac5285d97f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c24f3ec44c8f4e6e9d0a458d4769e7dc","placeholder":"​","style":"IPY_MODEL_7d414adf47c1436f890bc41eb36b2985","value":"Downloading data files: 100%"}},"cd581bd64e4646e6b7e4ad68c640d24e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbad717968dc401c94655e2989f5594f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68794194a7ec42efa7e0bab6f0f61822","value":1}},"1e927639569b41ad890b8b91ced4fc13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14048033409f47aab67abb817828124b","placeholder":"​","style":"IPY_MODEL_c572cbbe43ec44dd8a1f4a90e9dfba0c","value":" 1/1 [00:00&lt;00:00, 65.77it/s]"}},"b378a4f36d7a47b29dae226be34a894e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c24f3ec44c8f4e6e9d0a458d4769e7dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d414adf47c1436f890bc41eb36b2985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbad717968dc401c94655e2989f5594f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68794194a7ec42efa7e0bab6f0f61822":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14048033409f47aab67abb817828124b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c572cbbe43ec44dd8a1f4a90e9dfba0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2758a653720d4dc895172f14f0aadd7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_389a10f527cb4a69b3a548428bdeeccf","IPY_MODEL_9e06a02f74904e67a82562956c474a5b","IPY_MODEL_1dc1bb9c761f430f944c6794956a60f1"],"layout":"IPY_MODEL_5eeb2e54fa4d412bae0f4360e3f8366e"}},"389a10f527cb4a69b3a548428bdeeccf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab3dd0fa61ec4e269b1d8e269ed5e7bc","placeholder":"​","style":"IPY_MODEL_34942a472e554a7682454e7d4cc4871a","value":"Extracting data files: 100%"}},"9e06a02f74904e67a82562956c474a5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5877e49fa4a4ab9937972a85b48d0b9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_026d19a814da4c11a8190475c17858be","value":1}},"1dc1bb9c761f430f944c6794956a60f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b89f7d03eed14b848deb83ecb29ec490","placeholder":"​","style":"IPY_MODEL_5f97c076255c4021a24baedcff4df7c5","value":" 1/1 [00:00&lt;00:00, 25.19it/s]"}},"5eeb2e54fa4d412bae0f4360e3f8366e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3dd0fa61ec4e269b1d8e269ed5e7bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34942a472e554a7682454e7d4cc4871a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5877e49fa4a4ab9937972a85b48d0b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"026d19a814da4c11a8190475c17858be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b89f7d03eed14b848deb83ecb29ec490":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f97c076255c4021a24baedcff4df7c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69f069c6997242d29dbf518621ef0e91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a939f0a078547f38c0c8d9f68d3a13c","IPY_MODEL_c9257235d33e4891a3c8bbb622d92438","IPY_MODEL_78327e6c264f4a819027e01036f63f6a"],"layout":"IPY_MODEL_8433ad68751e452d98cc475e15caa46a"}},"0a939f0a078547f38c0c8d9f68d3a13c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c23000cfc80742c998152cebd5df922c","placeholder":"​","style":"IPY_MODEL_09de039a70a949f9b3a524eedf065c0a","value":"Generating train split: "}},"c9257235d33e4891a3c8bbb622d92438":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b8003b355dd458b85f9002e2b8d4f73","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc5b349b253d4dae92f95d62c4a93440","value":1}},"78327e6c264f4a819027e01036f63f6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda3769438aa4075a57fc388943538fd","placeholder":"​","style":"IPY_MODEL_e98ac0a61f7f450daace245778c8c704","value":" 4560/0 [00:00&lt;00:00, 39428.28 examples/s]"}},"8433ad68751e452d98cc475e15caa46a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c23000cfc80742c998152cebd5df922c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09de039a70a949f9b3a524eedf065c0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b8003b355dd458b85f9002e2b8d4f73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bc5b349b253d4dae92f95d62c4a93440":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dda3769438aa4075a57fc388943538fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e98ac0a61f7f450daace245778c8c704":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b4fb436ce9146acb54cfaf0abdb1672":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37ab3e2eec5646c5ad29e4d8792d29fb","IPY_MODEL_634b2e9ee23947aa9a9392b439712f04","IPY_MODEL_32d7f0591623498582bf8460f88955fe"],"layout":"IPY_MODEL_711cc82ae4444bf38152a7d0c27fa199"}},"37ab3e2eec5646c5ad29e4d8792d29fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db539b7e7a96413fbc37a0cd9c6ecbc5","placeholder":"​","style":"IPY_MODEL_6e43acf202eb41d49cb7cb6cfc5931ca","value":"100%"}},"634b2e9ee23947aa9a9392b439712f04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fad06385b0a349efadb0b923182d1499","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb1b98753d764e209b38cf32e70819b4","value":1}},"32d7f0591623498582bf8460f88955fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b5aa54f0318407e98ddd9e3b822e304","placeholder":"​","style":"IPY_MODEL_863515d8fcec435bb96a00c10732c76b","value":" 1/1 [00:00&lt;00:00, 46.22it/s]"}},"711cc82ae4444bf38152a7d0c27fa199":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db539b7e7a96413fbc37a0cd9c6ecbc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e43acf202eb41d49cb7cb6cfc5931ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fad06385b0a349efadb0b923182d1499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb1b98753d764e209b38cf32e70819b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b5aa54f0318407e98ddd9e3b822e304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"863515d8fcec435bb96a00c10732c76b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"926903256f124c9c9398b91e4da5c283":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59085e7b150d49ccae4902d38924a718","IPY_MODEL_10ef58f5b2f9432c8be386c41fb34866","IPY_MODEL_d7b9a924d7dc4500827f66d61bd5e6c6"],"layout":"IPY_MODEL_82cd6c3bac9f497b9ed75f5c49e71e5e"}},"59085e7b150d49ccae4902d38924a718":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a2ed3ea0374757a7fa2db85ff23b1a","placeholder":"​","style":"IPY_MODEL_3c707d33912f42a7a61ee02b509727cc","value":"Map:  97%"}},"10ef58f5b2f9432c8be386c41fb34866":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_80d8caef21c14d2e8d36c5ad4d8b5872","max":4104,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90aa1067c9b248f6b00b38fe9fb6c125","value":4104}},"d7b9a924d7dc4500827f66d61bd5e6c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a505ad26a36443f932196310f414ab4","placeholder":"​","style":"IPY_MODEL_0c1210bca6184fcd89ed53bc2a1b43e3","value":" 4000/4104 [00:04&lt;00:00, 963.07 examples/s]"}},"82cd6c3bac9f497b9ed75f5c49e71e5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"55a2ed3ea0374757a7fa2db85ff23b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c707d33912f42a7a61ee02b509727cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80d8caef21c14d2e8d36c5ad4d8b5872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90aa1067c9b248f6b00b38fe9fb6c125":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a505ad26a36443f932196310f414ab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c1210bca6184fcd89ed53bc2a1b43e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f41efaf15b44809bd2587155a30089e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fb62f515d874fac8027c998db9b26f8","IPY_MODEL_0c4c68fbfaaf4a498455aa295e9a4055","IPY_MODEL_6d237799080e4082b25b53f49d0d16b3"],"layout":"IPY_MODEL_4cc939ca5d8046e8b3cf8127811a0127"}},"1fb62f515d874fac8027c998db9b26f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d520df425f349ed90999d2f00a97a6d","placeholder":"​","style":"IPY_MODEL_2176844ca0d7483896d51418aec67ac1","value":"Map: 100%"}},"0c4c68fbfaaf4a498455aa295e9a4055":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_040031e765b342bea8722bddaeb06827","max":228,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5b3b56aae16490da8b41c1a6d7d368b","value":228}},"6d237799080e4082b25b53f49d0d16b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6710646a9269438486387341785c0b28","placeholder":"​","style":"IPY_MODEL_cbc2978c9f704040b6562807918b15d5","value":" 228/228 [00:00&lt;00:00, 977.47 examples/s]"}},"4cc939ca5d8046e8b3cf8127811a0127":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"5d520df425f349ed90999d2f00a97a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2176844ca0d7483896d51418aec67ac1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"040031e765b342bea8722bddaeb06827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5b3b56aae16490da8b41c1a6d7d368b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6710646a9269438486387341785c0b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbc2978c9f704040b6562807918b15d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf017422631941a08b986d4976b7c662":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b8332de1aa84f58bbb748f0fff659a7","IPY_MODEL_e8aeb05bbd054cfa9fe9fe33aa550b30","IPY_MODEL_d8fe536a4dcb4702b964215053b80652"],"layout":"IPY_MODEL_29018ef9dc6e4749b02134c5f68a9f31"}},"5b8332de1aa84f58bbb748f0fff659a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d197e5f675954cc780e2a1b35b1f653f","placeholder":"​","style":"IPY_MODEL_b7dbf6279a584b8eb9f7f6108017bb4d","value":"Map: 100%"}},"e8aeb05bbd054cfa9fe9fe33aa550b30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5771419be03a4366a268a46339a25e9f","max":228,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b8e4d60a69c4d51ac15e39cecba8d44","value":228}},"d8fe536a4dcb4702b964215053b80652":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e254d713c5364450afb51f224144d405","placeholder":"​","style":"IPY_MODEL_dfa8ae6977784baf8e4646f8f0e2e490","value":" 228/228 [00:00&lt;00:00, 1080.34 examples/s]"}},"29018ef9dc6e4749b02134c5f68a9f31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d197e5f675954cc780e2a1b35b1f653f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7dbf6279a584b8eb9f7f6108017bb4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5771419be03a4366a268a46339a25e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8e4d60a69c4d51ac15e39cecba8d44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e254d713c5364450afb51f224144d405":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa8ae6977784baf8e4646f8f0e2e490":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0de14e03ce45429e93a454f47ecc99c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ddfbe19dd1be4ad6b6dae4495027e93a","IPY_MODEL_e5c6c12c71d14fd6a86c26469d50014d","IPY_MODEL_ceaab972127249a4ad854044f0112ec9"],"layout":"IPY_MODEL_c90f10825ac64061a73db18bbfdcb157"}},"ddfbe19dd1be4ad6b6dae4495027e93a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b73a99b9f6fa419cae1a581d81fcd0d9","placeholder":"​","style":"IPY_MODEL_d07a444061154597945446d46f36afc8","value":"Map:  97%"}},"e5c6c12c71d14fd6a86c26469d50014d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1175bc0ae0854017a02be20ec5cf9f14","max":4104,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ecc07a88c4634307a9f68541f096603e","value":4104}},"ceaab972127249a4ad854044f0112ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c594616cbbcc4a0f8ad81ac617efdd14","placeholder":"​","style":"IPY_MODEL_c45b139df2ed4c769a7636bae30758dc","value":" 4000/4104 [00:02&lt;00:00, 1903.24 examples/s]"}},"c90f10825ac64061a73db18bbfdcb157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"b73a99b9f6fa419cae1a581d81fcd0d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d07a444061154597945446d46f36afc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1175bc0ae0854017a02be20ec5cf9f14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecc07a88c4634307a9f68541f096603e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c594616cbbcc4a0f8ad81ac617efdd14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45b139df2ed4c769a7636bae30758dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72e06bad36c84d05bebc1fc20da80f90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ea34d33d6684eac90a45b8d7a6753f0","IPY_MODEL_5876e1eefc3a40b49cc5068204063146","IPY_MODEL_9bb44881d71d4135b4492f58d4ab7e06"],"layout":"IPY_MODEL_ee1fd3afd2344f21b1f860ddbe5aa4aa"}},"2ea34d33d6684eac90a45b8d7a6753f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4250d5dcafe948e8b0ee1bb789c400f4","placeholder":"​","style":"IPY_MODEL_6a15921bcc204f30b59f490c40ff2594","value":"Map: 100%"}},"5876e1eefc3a40b49cc5068204063146":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e94dd0b0e914f23bc2314175ecf37a0","max":228,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b90cd4677db4656904170135bab6343","value":228}},"9bb44881d71d4135b4492f58d4ab7e06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38fed8d39b86497dbd5e706a982e8283","placeholder":"​","style":"IPY_MODEL_e1d92bf0ff2b4204a7cde57cdce70385","value":" 228/228 [00:00&lt;00:00, 1601.15 examples/s]"}},"ee1fd3afd2344f21b1f860ddbe5aa4aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4250d5dcafe948e8b0ee1bb789c400f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a15921bcc204f30b59f490c40ff2594":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e94dd0b0e914f23bc2314175ecf37a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b90cd4677db4656904170135bab6343":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38fed8d39b86497dbd5e706a982e8283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1d92bf0ff2b4204a7cde57cdce70385":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c03608be16b04104bea749cb2b3fe6e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cf8a3fb0f6e47e289266a0063206233","IPY_MODEL_9d06addd3e1749a2ba3b74710ffaf0b2","IPY_MODEL_83274010e3d7430ebe119bd895a33b73"],"layout":"IPY_MODEL_2e91bb113de64e569113f2b99c903ed6"}},"5cf8a3fb0f6e47e289266a0063206233":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c82c6f12dbcf4cd5a97e3c25055db050","placeholder":"​","style":"IPY_MODEL_16b43eaba81948208246b781fec762a6","value":"Map: 100%"}},"9d06addd3e1749a2ba3b74710ffaf0b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a13105150494d13ac6ac2afb72cf400","max":228,"min":0,"orientation":"horizontal","style":"IPY_MODEL_192a22e0b4544676bc97009cc375fcea","value":228}},"83274010e3d7430ebe119bd895a33b73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54bf5be21de94c93b710a949b18fb10a","placeholder":"​","style":"IPY_MODEL_d151bab5abed48b0838498e500268e56","value":" 228/228 [00:00&lt;00:00, 1684.41 examples/s]"}},"2e91bb113de64e569113f2b99c903ed6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c82c6f12dbcf4cd5a97e3c25055db050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b43eaba81948208246b781fec762a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a13105150494d13ac6ac2afb72cf400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"192a22e0b4544676bc97009cc375fcea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54bf5be21de94c93b710a949b18fb10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d151bab5abed48b0838498e500268e56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This is the code I have written in order to implement the miniproject \"Episodes' Title Generation\" (ETG)."],"metadata":{"id":"7f6NWaTDdN98"}},{"cell_type":"markdown","source":["# Installation, import, global variables"],"metadata":{"id":"yF6KO5td8rFE"}},{"cell_type":"code","source":["!pip install evaluate > /dev/null\n","!pip install transformers > /dev/null\n","!pip install datasets > /dev/null\n","!pip install accelerate > /dev/null\n","!pip install rouge_score > /dev/null"],"metadata":{"id":"QfY2g6jer7wj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset, load_dataset, load_metric\n","import math\n","import nltk\n","from nltk.tokenize import sent_tokenize,word_tokenize\n","import numpy as np\n","from numpy.linalg import norm\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig, \\\n","                         DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, \\\n","                         DataCollatorForLanguageModeling, DataCollatorWithPadding, \\\n","                         GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n","import evaluate\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics.pairwise import cosine_similarity\n","import pandas as pd\n","import torch\n","\n","import zipfile\n","import gdown\n","import os"],"metadata":{"id":"ZKs7Oh48sIlr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GF5mE_VmsMN4","outputId":"c85966b5-9aea-4700-92fa-43898c4b1695","executionInfo":{"status":"ok","timestamp":1686295554300,"user_tz":-120,"elapsed":865,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["already_trained = True"],"metadata":{"id":"MQitN3WpJb1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"gHLKkFkbJcdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download dataset and models from Google Drive to use them locally\n","\n","FILE_ID_dataset = \"14StcfnmUjQOvXI9xZAM9BeEyuzW3F5Nq\"\n","gdown.download(f\"https://drive.google.com/uc?export=download&id={FILE_ID_dataset}\", \"./series.zip\", quiet=False)\n","\n","if already_trained:\n","  FILE_ID_distilGPT2 = \"150D-EpoMKozIwSKiS4sNG7Z4Je8mxODO\"\n","  FILE_ID_T5 = \"1wtta7aRBen2vJQlInTtPAJEqi2TvDsIg\"\n","\n","  gdown.download(f\"https://drive.google.com/uc?export=download&id={FILE_ID_distilGPT2}\", \"./model-distil-gpt2.zip\", quiet=False)\n","  gdown.download(f\"https://drive.google.com/uc?export=download&id={FILE_ID_T5}\", \"./model-t5-base.zip\", quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"ym1o5CU3xz2z","executionInfo":{"status":"ok","timestamp":1686295596596,"user_tz":-120,"elapsed":42299,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"b4ff6c59-b787-4602-bb23-c0435bf457e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?export=download&id=14StcfnmUjQOvXI9xZAM9BeEyuzW3F5Nq\n","To: /content/series.zip\n","100%|██████████| 916k/916k [00:00<00:00, 113MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?export=download&id=150D-EpoMKozIwSKiS4sNG7Z4Je8mxODO\n","To: /content/model-distil-gpt2.zip\n","100%|██████████| 305M/305M [00:01<00:00, 153MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?export=download&id=1wtta7aRBen2vJQlInTtPAJEqi2TvDsIg\n","To: /content/model-t5-base.zip\n","100%|██████████| 2.45G/2.45G [00:36<00:00, 67.4MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'./model-t5-base.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["def extraction_from_zip(path_zip,path_unzip):\n","      if os.path.exists(path_zip):\n","          print(f\"Extracting the archive {path_zip}...\")\n","          with zipfile.ZipFile(path_zip, 'r') as zip_ref:\n","              zip_ref.extractall(path_unzip)\n","          print(\"Done.\")\n","          os.remove(path_zip) \n","\n","extraction_from_zip(\"./series.zip\",\"/content/\")\n","\n","if already_trained:\n","  extraction_from_zip(\"./model-distil-gpt2.zip\",\"/content/\")\n","  extraction_from_zip(\"./model-t5-base.zip\",\"/content/model-t5-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHfvoZJvybNV","executionInfo":{"status":"ok","timestamp":1686295626431,"user_tz":-120,"elapsed":29846,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"195960c4-2347-40e8-9b47-9ac7b30aa3c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting the archive ./series.zip...\n","Done.\n","Extracting the archive ./model-distil-gpt2.zip...\n","Done.\n","Extracting the archive ./model-t5-base.zip...\n","Done.\n"]}]},{"cell_type":"code","source":["dataset_path = \"/content/series.csv\" \n","\n","if already_trained:\n","  model_path_gpt = \"/content/model-distil-gpt2\" \n","  model_path_t5 = \"/content/model-t5-base\" "],"metadata":{"id":"NXhKLYvFANZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the tokenizer the GPT2 model will use, using the Huggingface Transformers class \"GPT2Tokenizer\"\n","gpt_tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["dc95ee02a98b40f0af5547c4976db112","f9eb9684d1ed4f8e84a746426f435e93","3143ee3d78d34b2d97389c2ab09ff44c","35346576b6fd4efaa64d8056a5937e39","e65d4419eede490e8ae1a53419cdaab2","1288360ecba5460a8e702f7bd5d9c4da","1618f5b1f43645afb00a1a837257b6cf","cff75ea575d14f0fb51549bac0701811","e3a849165fd04eb4836e37e919d85abb","f3fe7a38847e47da8da8a228c21fd05a","2b866fd72aea4354b5b831d2eeb44773","42dae7f3cc554461a2da97ebb71ae095","5ec8f2d1c0ae431ab6b3445459916ec1","0f02df2a969545a3a020deec76bca219","22820aa70c4a43b8b7093e1d6fc088c7","34975aba931d47d18fda98c62b35a6ac","55945eceecd3424da09d6fea0f4b7765","f5f8c7fc5ec34339be3650bc07918586","534af7fc78564b4bb151ddd87926b323","8cb9e49aaadb49dc887e64c83adaa388","fc82c3272fa8465982ab7d8f70ec11d9","47a07345e0814445b7c205532c2f2e19","2df8243c9139477587865ebf7b082555","8104da9a1d5447208df1ac82161092f5","c5e7163e1c1849f88accf8ea4f368113","6ed405186a6747c3ac4240ec6d071686","d52e29c372434228b9f4842778b1e8cb","173cb086bb7b4f5d9c91eb88eec4e9c8","c5a8f6c010c24f6c9b68036183e56bd4","2058a629eec3405ba4112085d4f93c3d","ad95a3586c5945ab83101972ebbb9340","c278ed39e18845d4bd309cd138765163","4c2b19f3b0b44a1385936f5655f0810b"],"height":113},"id":"Yvi5mG7MJlyc","outputId":"eec0e477-4da0-4166-8098-3de1211f03dc","executionInfo":{"status":"ok","timestamp":1686295627592,"user_tz":-120,"elapsed":1180,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc95ee02a98b40f0af5547c4976db112"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42dae7f3cc554461a2da97ebb71ae095"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df8243c9139477587865ebf7b082555"}},"metadata":{}}]},{"cell_type":"code","source":["# Definition of special tokens \n","bos = '<|endoftext|>'\n","eos = '<|EOS|>'\n","title_tkn = '<|title|>'\n","\n","special_tokens_dict = {'eos_token': eos, 'bos_token': bos, 'pad_token': '<|pad|>',\n","                       'sep_token': title_tkn}\n","\n","# Add special tokens to the tokenizer\n","num_added_toks = gpt_tokenizer.add_special_tokens(special_tokens_dict)\n","\n","# Add special tokens to the model using model configuration\n","config = AutoConfig.from_pretrained('distilgpt2', \n","                                    bos_token_id=gpt_tokenizer.bos_token_id,\n","                                    eos_token_id=gpt_tokenizer.eos_token_id,\n","                                    pad_token_id=gpt_tokenizer.pad_token_id,\n","                                    sep_token_id=gpt_tokenizer.sep_token_id,\n","                                    output_hidden_states=False)\n","\n","# Loading the model distil-GPT2 using the Huggingface Transformers class \"GPT2LMHeadModel\" and the custom configuration\n","gpt_model = GPT2LMHeadModel.from_pretrained('distilgpt2', config=config)\n","\n","# Model embedding resizing\n","gpt_model.resize_token_embeddings(len(gpt_tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["7a3038acd7d342de8afeba8026bd0a62","d7c3a5b2f88f4306add385c481ae294a","0c0db7f6bbd8405ea4497f3ddc49b85c","f0b62a538f7c48feb0c83b722fc57813","3b1e5c8837e542249d4c5b6307f34456","22b1f43c02214f9e9b5a209dd0ec3709","c953f417d5b244489cf34d8a8ab5b79d","9d576e004e0c416c9e0cc5ace5d1f0fd","c96d963cccc741c3bb88c75c54443d25","ecb2a9fe4e5149a982d621bdf33749b7","e4f867f683b54c3d858493db6c3b116c","f3fcafa024d6401887e6884a770d0722","866ab6d705fd49009572ba59c6be4964","6340aece0ca542d78acc862e41f47333","d661208e84784f3794b1bcff554bf5ca","2a4ff7c6b4cb42039fd9b3251610f094","e0683182380248838214a31899e684d2","c822fb67fb88480089d7e9f655209f2a","fbfbb665cd0c43f6a2d096cc4e363efb","52a9d88e327d4f7f994d1d7d7f8efebf","edab427abe7a419ca6003c1ae9246aac","04e582e6b8f948dd968ec89417216bc6"],"height":98},"id":"SWwM4tgMJnc2","outputId":"89253b54-502e-4cfa-83ff-19b4971f7576","executionInfo":{"status":"ok","timestamp":1686295634304,"user_tz":-120,"elapsed":6748,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a3038acd7d342de8afeba8026bd0a62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3fcafa024d6401887e6884a770d0722"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Embedding(50260, 768)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Loading the tokenizer that the T5 model will use, using the Huggingface Transformers class \"AutoTokenizer\"\n","t5_tokenizer = AutoTokenizer.from_pretrained('t5-base')"],"metadata":{"executionInfo":{"status":"ok","timestamp":1685993670656,"user_tz":-120,"elapsed":3166,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["6d60430491c64b19b99b3dd92347f7c5","9572d032cfa345ea86cc9a8881e81cef","e06a2711579f4c8aab89400c0395c109","7f3aa6d94a0a493f8a93ac457f3d6c75","5fea08a2068a438f8c3c1e8022f7209c","a3adce8ab9a54a5e9abecf8c690a82d1","b1b572269e174f0f978a97d9d8df31eb","a74222607dbd4d3484552f5c398473a3","480517d999e246b8b0b4d3c2640c0268","fa9f17ef89dd4eea8a3da92b5b0af968","6cca392a7ab54dcaa5beb42f0b7d34e5","1738571c93e24286ae48aa3c3f48630c","f46fd6f31abf4b5eba3a961482dc506a","bfc4c568bfcf4a668bbaced654eca4ee","c974be9bff6b4c0f820fadb5bd03b5e8","fea8b4262a4f45698e96cfb3554bde32","0e5c4c871624477ca169c438d6d67452","94e7b86cd8b9457d90360d5fd1da5fe6","1b13e6b19451440cb5fe55eb06a570b6","b8198025e89c48aab679bfa5af101f4b","af154c0522b843d89bf1d8b400457438","f047ba88e3234e699c6da8b027ab458a","973680bb4dcc4c7dbbd6aa88d2edbe42","7a43e081fd524469a66d61458edb936f","735869d94acb48bcb36aa6142fef12d8","3e034e8c37634b0f9968f62aa6ee678d","6a50355240364fc29a415b0d679a00da","9c0cb98311594fb19a4ed12dddbb04ef","ed0a5f5556424f7bba182e1145a04660","6a9840173b754511b3060d29dff784be","f3ecc0055f2b407a9a0ba2bd257293eb","3a35fa31a33348a2bdf3a3a2e72ab4a5","f7b7d3e13e4841309c3afcf3d67a87b3"],"height":237},"outputId":"da5abe7c-be23-49c7-c972-72eb9917608f","id":"DHwi0PSPG_o9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d60430491c64b19b99b3dd92347f7c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1738571c93e24286ae48aa3c3f48630c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"973680bb4dcc4c7dbbd6aa88d2edbe42"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Loading the T5-base model using the Huggingface Transformers class \"AutoModelForSeq2SeqLM\"\n","t5_model = AutoModelForSeq2SeqLM.from_pretrained('t5-base').to(\"cuda\")"],"metadata":{"id":"kq5fXB6_sktI","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["2c33608d08d44e79b94a9d0c0b6d2f36","28c24f9873ff4756a3d8e38250a3089f","4b916b5f5eb743f09b236f8d831b97e7","3789d49d18bd47f7afdacae15e7d00e9","501abc81079d4ba88842686e397e8b48","874da387dc2a446785c8a14feae33cda","a6f364d2ed164b6eafe0b3d750716aab","c163d77b650348d49e8411c61ebd7c63","95c3137708764db4802bf8e881f9ae7b","4ce8554c21c5492ca01a1aa2860d2356","1482e2d7bedf407eb21688947150b855","0e50ca31a464467082ce1f04bcaeaeb3","2a2e9bb9f5784c4bac6c4796ae566b58","73da7c6fcf7d42c7a121fd9a3e5dd8f7","e2cba565bf8c41b58a205520329dbd94","5b88f2b0975d42cf9056a74f87722768","673e0d274532479aaf78f88a7dcc67ea","7a2219e9d1d14826afb8b9f384e42a3a","1d6bbe9e9c4642b1a1330c548ab407fb","98260da3938e45e39788a07ab7c24607","583ef3851588465d9f5828f4268fd51d","dada19947a9145ebabd2635bf1388c2e"],"height":81},"outputId":"fb441454-15ec-426d-c122-49a147b0027d","executionInfo":{"status":"ok","timestamp":1686295643177,"user_tz":-120,"elapsed":6913,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c33608d08d44e79b94a9d0c0b6d2f36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e50ca31a464467082ce1f04bcaeaeb3"}},"metadata":{}}]},{"cell_type":"code","source":["# Global variables for the training phase\n","batch_size = 8\n","num_epochs = 5\n","learning_rate = 1e-5\n","weight_decay = 0.001\n","log_every = 50\n","eval_every = 50\n","lr_scheduler_type = \"linear\"\n","\n","# Parameter for the generation of new titles when using T5 model\n","max_gen_length = 128\n","\n","# Global variable for the beam search\n","num_beams = 4\n","\n","# Global variables for the Top-P, Top-K sampling\n","no_repeat_ngram_size = 2\n","repetition_penalty = 1.5\n","top_p=0.9\n","temperature=0.85\n","top_k=50"],"metadata":{"id":"8tTDZksbdlk4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Dataset"],"metadata":{"id":"ToWlN7pdw6aG"}},{"cell_type":"markdown","source":["The data for dataset building has been collected using a custom-made scraper  which gets entries from Wikipedia. The result of the scraper is a csv file made of two columns: TITLE and PLOT. I have collected data from 30 American television sitcoms reaching a total of 4560 episodes thus 4560 entries."],"metadata":{"id":"Y-vWSrp5yT9o"}},{"cell_type":"markdown","source":["## Maximum length computations (for model T5)"],"metadata":{"id":"Dm_IIhDqcOH3"}},{"cell_type":"markdown","source":["Concerning the T5 model, I need to know what the maximum length both for tokenized plots and tokenized titles will be, in order to pass the parameter max_length to the tokenizer, to compute the padding."],"metadata":{"id":"iKJlhVwWp30-"}},{"cell_type":"code","source":["dataset = load_dataset(\"csv\", data_files=dataset_path, sep='\\t')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["d4939cf24a6142f6a5944ad1de54b987","60b3557649cf44d292142aac5285d97f","cd581bd64e4646e6b7e4ad68c640d24e","1e927639569b41ad890b8b91ced4fc13","b378a4f36d7a47b29dae226be34a894e","c24f3ec44c8f4e6e9d0a458d4769e7dc","7d414adf47c1436f890bc41eb36b2985","dbad717968dc401c94655e2989f5594f","68794194a7ec42efa7e0bab6f0f61822","14048033409f47aab67abb817828124b","c572cbbe43ec44dd8a1f4a90e9dfba0c","2758a653720d4dc895172f14f0aadd7f","389a10f527cb4a69b3a548428bdeeccf","9e06a02f74904e67a82562956c474a5b","1dc1bb9c761f430f944c6794956a60f1","5eeb2e54fa4d412bae0f4360e3f8366e","ab3dd0fa61ec4e269b1d8e269ed5e7bc","34942a472e554a7682454e7d4cc4871a","a5877e49fa4a4ab9937972a85b48d0b9","026d19a814da4c11a8190475c17858be","b89f7d03eed14b848deb83ecb29ec490","5f97c076255c4021a24baedcff4df7c5","69f069c6997242d29dbf518621ef0e91","0a939f0a078547f38c0c8d9f68d3a13c","c9257235d33e4891a3c8bbb622d92438","78327e6c264f4a819027e01036f63f6a","8433ad68751e452d98cc475e15caa46a","c23000cfc80742c998152cebd5df922c","09de039a70a949f9b3a524eedf065c0a","8b8003b355dd458b85f9002e2b8d4f73","bc5b349b253d4dae92f95d62c4a93440","dda3769438aa4075a57fc388943538fd","e98ac0a61f7f450daace245778c8c704","8b4fb436ce9146acb54cfaf0abdb1672","37ab3e2eec5646c5ad29e4d8792d29fb","634b2e9ee23947aa9a9392b439712f04","32d7f0591623498582bf8460f88955fe","711cc82ae4444bf38152a7d0c27fa199","db539b7e7a96413fbc37a0cd9c6ecbc5","6e43acf202eb41d49cb7cb6cfc5931ca","fad06385b0a349efadb0b923182d1499","bb1b98753d764e209b38cf32e70819b4","2b5aa54f0318407e98ddd9e3b822e304","863515d8fcec435bb96a00c10732c76b"],"height":168},"id":"nfTw0i4hvNBK","outputId":"27030090-b24e-47a2-daa9-5218e23055b5","executionInfo":{"status":"ok","timestamp":1686295643712,"user_tz":-120,"elapsed":553,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-e15b065befe7a53d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4939cf24a6142f6a5944ad1de54b987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2758a653720d4dc895172f14f0aadd7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69f069c6997242d29dbf518621ef0e91"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-e15b065befe7a53d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4fb436ce9146acb54cfaf0abdb1672"}},"metadata":{}}]},{"cell_type":"code","source":["plots = []\n","titles = []\n","for t in dataset['train']:\n","    titles.append(t[\"TITLE\"])\n","    plots.append(t[\"PLOT\"])"],"metadata":{"id":"LjEkwarodkri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def maxLengthComputation(items_set):\n","    max_len = 0\n","    for i in items_set:\n","        input_ids = t5_tokenizer.encode(i)\n","        if len(input_ids) > max_len:\n","            max_len = len(input_ids)\n","    return max_len\n","\n","MAX_SOURCE_LEN = maxLengthComputation(plots)\n","print(f\"MAX_SOURCE_LEN: {MAX_SOURCE_LEN}\")\n","MAX_TARGET_LEN = maxLengthComputation(titles)\n","print(f\"MAX_TARGET_LEN: {MAX_TARGET_LEN}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnXZN5n_cCka","outputId":"8bd377d9-c710-4cb2-9c68-e213b6ac2d82","executionInfo":{"status":"ok","timestamp":1686295645892,"user_tz":-120,"elapsed":1766,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["MAX_SOURCE_LEN: 629\n","MAX_TARGET_LEN: 26\n"]}]},{"cell_type":"markdown","source":["## Dataset creation"],"metadata":{"id":"UrScRUmhrAxZ"}},{"cell_type":"markdown","source":["Here I create datasets for training, validation and testing using *sklearn.model_selection.train_test_split* which splits into random train and test subsets. "],"metadata":{"id":"4F853iIssr7Q"}},{"cell_type":"code","source":["episodes_df = pd.read_csv(dataset_path, sep='\\t', encoding = 'utf-8')"],"metadata":{"id":"o03GWDvBMRdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["episodes_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"BwGdruqLMh9P","outputId":"400d9f7a-c471-4d20-fc4b-e4fb9ace9c06","executionInfo":{"status":"ok","timestamp":1686295645894,"user_tz":-120,"elapsed":55,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  TITLE  \\\n","0                                                 Pilot   \n","1                          And the Rich People Problems   \n","2                              And the '90s Horse Party   \n","3                                And the Break-up Scene   \n","4                               And Strokes of Goodwill   \n","...                                                 ...   \n","4555                 Body Glitter and a Mall Safety Kit   \n","4556     An Entrepreneurialist and a Swat on the Bottom   \n","4557  A Live Chicken, a Fried Chicken, and Holy Matr...   \n","4558  A Solar Calculator, a Game Ball, and a Cheerle...   \n","4559                     A Patch, a Modem, and a Zantac   \n","\n","                                                   PLOT  \n","0     Russian waitress Paulina is fired from the din...  \n","1     Max is for once overwhelmed and impressed when...  \n","2     After discovering how many debts Max is dodgin...  \n","3     Caroline thinks she is doing Max a favor when ...  \n","4     Max takes Caroline thrift shopping. After seei...  \n","...                                                 ...  \n","4555  Paige's parents get a divorce, leading to Paig...  \n","4556  Dr. Linkletter, wanting to create additional o...  \n","4557  Pastor Jeff and Officer Robin rush to get marr...  \n","4558  Sheldon uses sports analytics to help his scho...  \n","4559  Dr. Ronald Hodges, a NASA engineer, appears as...  \n","\n","[4560 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-f4be0832-b01d-46d6-9c98-8a5811dc7a7e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>PLOT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Pilot</td>\n","      <td>Russian waitress Paulina is fired from the din...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>And the Rich People Problems</td>\n","      <td>Max is for once overwhelmed and impressed when...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>And the '90s Horse Party</td>\n","      <td>After discovering how many debts Max is dodgin...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>And the Break-up Scene</td>\n","      <td>Caroline thinks she is doing Max a favor when ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>And Strokes of Goodwill</td>\n","      <td>Max takes Caroline thrift shopping. After seei...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4555</th>\n","      <td>Body Glitter and a Mall Safety Kit</td>\n","      <td>Paige's parents get a divorce, leading to Paig...</td>\n","    </tr>\n","    <tr>\n","      <th>4556</th>\n","      <td>An Entrepreneurialist and a Swat on the Bottom</td>\n","      <td>Dr. Linkletter, wanting to create additional o...</td>\n","    </tr>\n","    <tr>\n","      <th>4557</th>\n","      <td>A Live Chicken, a Fried Chicken, and Holy Matr...</td>\n","      <td>Pastor Jeff and Officer Robin rush to get marr...</td>\n","    </tr>\n","    <tr>\n","      <th>4558</th>\n","      <td>A Solar Calculator, a Game Ball, and a Cheerle...</td>\n","      <td>Sheldon uses sports analytics to help his scho...</td>\n","    </tr>\n","    <tr>\n","      <th>4559</th>\n","      <td>A Patch, a Modem, and a Zantac</td>\n","      <td>Dr. Ronald Hodges, a NASA engineer, appears as...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4560 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4be0832-b01d-46d6-9c98-8a5811dc7a7e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f4be0832-b01d-46d6-9c98-8a5811dc7a7e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f4be0832-b01d-46d6-9c98-8a5811dc7a7e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["episodes_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"og4aisDAM7vk","outputId":"df6bf1a8-0b81-4785-dfeb-37f134521510","executionInfo":{"status":"ok","timestamp":1686295645894,"user_tz":-120,"elapsed":52,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  TITLE  \\\n","0                                                 Pilot   \n","1                          And the Rich People Problems   \n","2                              And the '90s Horse Party   \n","3                                And the Break-up Scene   \n","4                               And Strokes of Goodwill   \n","...                                                 ...   \n","4555                 Body Glitter and a Mall Safety Kit   \n","4556     An Entrepreneurialist and a Swat on the Bottom   \n","4557  A Live Chicken, a Fried Chicken, and Holy Matr...   \n","4558  A Solar Calculator, a Game Ball, and a Cheerle...   \n","4559                     A Patch, a Modem, and a Zantac   \n","\n","                                                   PLOT  \n","0     Russian waitress Paulina is fired from the din...  \n","1     Max is for once overwhelmed and impressed when...  \n","2     After discovering how many debts Max is dodgin...  \n","3     Caroline thinks she is doing Max a favor when ...  \n","4     Max takes Caroline thrift shopping. After seei...  \n","...                                                 ...  \n","4555  Paige's parents get a divorce, leading to Paig...  \n","4556  Dr. Linkletter, wanting to create additional o...  \n","4557  Pastor Jeff and Officer Robin rush to get marr...  \n","4558  Sheldon uses sports analytics to help his scho...  \n","4559  Dr. Ronald Hodges, a NASA engineer, appears as...  \n","\n","[4560 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-cc037350-8c88-4d9d-8786-74c9e9c94862\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>PLOT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Pilot</td>\n","      <td>Russian waitress Paulina is fired from the din...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>And the Rich People Problems</td>\n","      <td>Max is for once overwhelmed and impressed when...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>And the '90s Horse Party</td>\n","      <td>After discovering how many debts Max is dodgin...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>And the Break-up Scene</td>\n","      <td>Caroline thinks she is doing Max a favor when ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>And Strokes of Goodwill</td>\n","      <td>Max takes Caroline thrift shopping. After seei...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4555</th>\n","      <td>Body Glitter and a Mall Safety Kit</td>\n","      <td>Paige's parents get a divorce, leading to Paig...</td>\n","    </tr>\n","    <tr>\n","      <th>4556</th>\n","      <td>An Entrepreneurialist and a Swat on the Bottom</td>\n","      <td>Dr. Linkletter, wanting to create additional o...</td>\n","    </tr>\n","    <tr>\n","      <th>4557</th>\n","      <td>A Live Chicken, a Fried Chicken, and Holy Matr...</td>\n","      <td>Pastor Jeff and Officer Robin rush to get marr...</td>\n","    </tr>\n","    <tr>\n","      <th>4558</th>\n","      <td>A Solar Calculator, a Game Ball, and a Cheerle...</td>\n","      <td>Sheldon uses sports analytics to help his scho...</td>\n","    </tr>\n","    <tr>\n","      <th>4559</th>\n","      <td>A Patch, a Modem, and a Zantac</td>\n","      <td>Dr. Ronald Hodges, a NASA engineer, appears as...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4560 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc037350-8c88-4d9d-8786-74c9e9c94862')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc037350-8c88-4d9d-8786-74c9e9c94862 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc037350-8c88-4d9d-8786-74c9e9c94862');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Split the dataset\n","df_train, test_val = train_test_split(episodes_df, train_size = 0.9, random_state = 77)\n","\n","df_val,df_test = train_test_split(test_val,test_size=0.5)"],"metadata":{"id":"y4V7FzRONJYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"ya8iomaGOo8G","outputId":"6b37d99c-af3c-4e01-9d17-901dc56b971a","executionInfo":{"status":"ok","timestamp":1686295645896,"user_tz":-120,"elapsed":51,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        TITLE  \\\n","3120                  The Gothowitz Deviation   \n","42                           And the Big Hole   \n","234            How Oliver Got His Groove Back   \n","1343              I Get a Sidekick Out of You   \n","376                             The Road Trip   \n","...                                       ...   \n","1317                    Jews and Chinese Food   \n","2283                         Jerry's Painting   \n","2004                                Flip Flop   \n","3668                      The Show Must Go On   \n","607   Don't Shoot...I'm Only the Psychiatrist   \n","\n","                                                   PLOT  \n","3120  Penny's bed in her apartment breaks, forcing h...  \n","42    After Han fires Caroline for disparaging the d...  \n","234   With Oliver reluctant to get over Lindsey's di...  \n","1343  Lane and Zach are getting married and they hav...  \n","376   When Jake and Amy have to stay at a B&B in ups...  \n","...                                                 ...  \n","1317  Still smarting from her split with Luke, Lorel...  \n","2283  Feeling frustrated and powerless because of he...  \n","2004  Gloria's ex-husband, Javiér introduces his new...  \n","3668  After almost forgetting that Brick's middle-sc...  \n","607   Cliff and Norm help Frasier's low-esteem self-...  \n","\n","[4104 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-d80927b8-5939-4c63-a175-d45b8283204b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>PLOT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3120</th>\n","      <td>The Gothowitz Deviation</td>\n","      <td>Penny's bed in her apartment breaks, forcing h...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>And the Big Hole</td>\n","      <td>After Han fires Caroline for disparaging the d...</td>\n","    </tr>\n","    <tr>\n","      <th>234</th>\n","      <td>How Oliver Got His Groove Back</td>\n","      <td>With Oliver reluctant to get over Lindsey's di...</td>\n","    </tr>\n","    <tr>\n","      <th>1343</th>\n","      <td>I Get a Sidekick Out of You</td>\n","      <td>Lane and Zach are getting married and they hav...</td>\n","    </tr>\n","    <tr>\n","      <th>376</th>\n","      <td>The Road Trip</td>\n","      <td>When Jake and Amy have to stay at a B&amp;B in ups...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1317</th>\n","      <td>Jews and Chinese Food</td>\n","      <td>Still smarting from her split with Luke, Lorel...</td>\n","    </tr>\n","    <tr>\n","      <th>2283</th>\n","      <td>Jerry's Painting</td>\n","      <td>Feeling frustrated and powerless because of he...</td>\n","    </tr>\n","    <tr>\n","      <th>2004</th>\n","      <td>Flip Flop</td>\n","      <td>Gloria's ex-husband, Javiér introduces his new...</td>\n","    </tr>\n","    <tr>\n","      <th>3668</th>\n","      <td>The Show Must Go On</td>\n","      <td>After almost forgetting that Brick's middle-sc...</td>\n","    </tr>\n","    <tr>\n","      <th>607</th>\n","      <td>Don't Shoot...I'm Only the Psychiatrist</td>\n","      <td>Cliff and Norm help Frasier's low-esteem self-...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4104 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d80927b8-5939-4c63-a175-d45b8283204b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d80927b8-5939-4c63-a175-d45b8283204b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d80927b8-5939-4c63-a175-d45b8283204b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["df_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"gBwy9_ZfOrVy","outputId":"6aa297ed-0a66-4bfd-b64f-cf8f8df6f391","executionInfo":{"status":"ok","timestamp":1686295645897,"user_tz":-120,"elapsed":51,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         TITLE  \\\n","186                                   Trust Me   \n","2499                      My Number One Doctor   \n","1484                                  The Duel   \n","3458  It's Better to Have Loved and Lost It...   \n","1546                        Not a Father's Day   \n","...                                        ...   \n","315                               The Honeypot   \n","1944                             Mother Tucker   \n","2385                  Fastest Criminal in Reno   \n","1551                          Little Minnesota   \n","4170                             Grandma's Pie   \n","\n","                                                   PLOT  \n","186   After Taylor lies about adult supervision at a...  \n","2499  Dr. Kelso signs the hospital up to RateYourDoc...  \n","1484  When Lily decides to formally move into Marsha...  \n","3458  Carlton meets Jo Ann, a beautiful woman on the...  \n","1546  Lily and Marshall receive different views on w...  \n","...                                                 ...  \n","315   While trying to find a new assistant, Jake and...  \n","1944  Mitchell tries to tell Cameron how he feels un...  \n","2385  The Reno Sheriff's Department gets a chance to...  \n","1551  It's Christmas time and Ted's younger sister, ...  \n","4170  Walden launches a new software app with his ol...  \n","\n","[228 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-5d8db3c8-3975-44b0-860b-e4008909c9c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>PLOT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>186</th>\n","      <td>Trust Me</td>\n","      <td>After Taylor lies about adult supervision at a...</td>\n","    </tr>\n","    <tr>\n","      <th>2499</th>\n","      <td>My Number One Doctor</td>\n","      <td>Dr. Kelso signs the hospital up to RateYourDoc...</td>\n","    </tr>\n","    <tr>\n","      <th>1484</th>\n","      <td>The Duel</td>\n","      <td>When Lily decides to formally move into Marsha...</td>\n","    </tr>\n","    <tr>\n","      <th>3458</th>\n","      <td>It's Better to Have Loved and Lost It...</td>\n","      <td>Carlton meets Jo Ann, a beautiful woman on the...</td>\n","    </tr>\n","    <tr>\n","      <th>1546</th>\n","      <td>Not a Father's Day</td>\n","      <td>Lily and Marshall receive different views on w...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>315</th>\n","      <td>The Honeypot</td>\n","      <td>While trying to find a new assistant, Jake and...</td>\n","    </tr>\n","    <tr>\n","      <th>1944</th>\n","      <td>Mother Tucker</td>\n","      <td>Mitchell tries to tell Cameron how he feels un...</td>\n","    </tr>\n","    <tr>\n","      <th>2385</th>\n","      <td>Fastest Criminal in Reno</td>\n","      <td>The Reno Sheriff's Department gets a chance to...</td>\n","    </tr>\n","    <tr>\n","      <th>1551</th>\n","      <td>Little Minnesota</td>\n","      <td>It's Christmas time and Ted's younger sister, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4170</th>\n","      <td>Grandma's Pie</td>\n","      <td>Walden launches a new software app with his ol...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>228 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d8db3c8-3975-44b0-860b-e4008909c9c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5d8db3c8-3975-44b0-860b-e4008909c9c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5d8db3c8-3975-44b0-860b-e4008909c9c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["df_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"7SJ9Y7aLOsOs","outputId":"348ff775-947f-44df-db74-d247b91830b1","executionInfo":{"status":"ok","timestamp":1686295645898,"user_tz":-120,"elapsed":50,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              TITLE  \\\n","4089                         Finale   \n","2414                  Back in Black   \n","2409      Dangle's Wedding (Part 1)   \n","3844  How to Lose a Mom in Ten Days   \n","1135         The One with Two Parts   \n","...                             ...   \n","185          Cheaters Sometimes Win   \n","2036      Sick Days & Spelling Bees   \n","478             Abnormal Psychology   \n","2991       The Helium Insufficiency   \n","2290                 Li'l Sebastian   \n","\n","                                                   PLOT  \n","4089  One year after the airing of the documentary, ...  \n","2414  Dangle (and an unwilling Williams) take time t...  \n","2409  Dangle's ex-wife's husband proposes to him. A ...  \n","3844  Mindy is tired of Annette hovering around her ...  \n","1135  Joey falls for Phoebe's identical twin sister,...  \n","...                                                 ...  \n","185   Katie's mother Kathryn arrives and immediately...  \n","2036  Ned must avoid getting sick during flu season ...  \n","478   Frasier reluctantly agrees to a talk-show deba...  \n","2991  Swedish physicists are about to prove Sheldon ...  \n","2290  Pawnee's favorite miniature horse, Li'l Sebast...  \n","\n","[228 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-d30415ab-eb58-4774-9b99-51caba17d506\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>PLOT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4089</th>\n","      <td>Finale</td>\n","      <td>One year after the airing of the documentary, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2414</th>\n","      <td>Back in Black</td>\n","      <td>Dangle (and an unwilling Williams) take time t...</td>\n","    </tr>\n","    <tr>\n","      <th>2409</th>\n","      <td>Dangle's Wedding (Part 1)</td>\n","      <td>Dangle's ex-wife's husband proposes to him. A ...</td>\n","    </tr>\n","    <tr>\n","      <th>3844</th>\n","      <td>How to Lose a Mom in Ten Days</td>\n","      <td>Mindy is tired of Annette hovering around her ...</td>\n","    </tr>\n","    <tr>\n","      <th>1135</th>\n","      <td>The One with Two Parts</td>\n","      <td>Joey falls for Phoebe's identical twin sister,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>185</th>\n","      <td>Cheaters Sometimes Win</td>\n","      <td>Katie's mother Kathryn arrives and immediately...</td>\n","    </tr>\n","    <tr>\n","      <th>2036</th>\n","      <td>Sick Days &amp; Spelling Bees</td>\n","      <td>Ned must avoid getting sick during flu season ...</td>\n","    </tr>\n","    <tr>\n","      <th>478</th>\n","      <td>Abnormal Psychology</td>\n","      <td>Frasier reluctantly agrees to a talk-show deba...</td>\n","    </tr>\n","    <tr>\n","      <th>2991</th>\n","      <td>The Helium Insufficiency</td>\n","      <td>Swedish physicists are about to prove Sheldon ...</td>\n","    </tr>\n","    <tr>\n","      <th>2290</th>\n","      <td>Li'l Sebastian</td>\n","      <td>Pawnee's favorite miniature horse, Li'l Sebast...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>228 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d30415ab-eb58-4774-9b99-51caba17d506')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d30415ab-eb58-4774-9b99-51caba17d506 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d30415ab-eb58-4774-9b99-51caba17d506');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["### Dataset for GPT-2"],"metadata":{"id":"YKZUWBUBK0C5"}},{"cell_type":"markdown","source":["Here I make the dataset compatible for the GPT model and thus I prepare the actual data that will be passed to the model."],"metadata":{"id":"Q0vzKtOMtumH"}},{"cell_type":"code","source":["# Thanks to the lamba function, I concatenate PLOT entry with TITLE entry using the separation token, for each row \n","prepare_text = lambda x: ' '.join([bos, x['PLOT'], title_tkn, x['TITLE'], eos])\n","\n","# I Introduce a new column 'text' for each set\n","df_train['text'] = df_train.apply(prepare_text, axis=1)\n","df_val['text'] = df_val.apply(prepare_text, axis=1)\n","df_test['text'] = df_test.apply(prepare_text, axis=1)"],"metadata":{"id":"fDRFhTMoK7px"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"id":"JAS_dZZ0LIYQ","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1686295646304,"user_tz":-120,"elapsed":14,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"1b3d2124-e331-4acc-b356-0ffbe8388283"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        TITLE  \\\n","3120                  The Gothowitz Deviation   \n","42                           And the Big Hole   \n","234            How Oliver Got His Groove Back   \n","1343              I Get a Sidekick Out of You   \n","376                             The Road Trip   \n","...                                       ...   \n","1317                    Jews and Chinese Food   \n","2283                         Jerry's Painting   \n","2004                                Flip Flop   \n","3668                      The Show Must Go On   \n","607   Don't Shoot...I'm Only the Psychiatrist   \n","\n","                                                   PLOT  \\\n","3120  Penny's bed in her apartment breaks, forcing h...   \n","42    After Han fires Caroline for disparaging the d...   \n","234   With Oliver reluctant to get over Lindsey's di...   \n","1343  Lane and Zach are getting married and they hav...   \n","376   When Jake and Amy have to stay at a B&B in ups...   \n","...                                                 ...   \n","1317  Still smarting from her split with Luke, Lorel...   \n","2283  Feeling frustrated and powerless because of he...   \n","2004  Gloria's ex-husband, Javiér introduces his new...   \n","3668  After almost forgetting that Brick's middle-sc...   \n","607   Cliff and Norm help Frasier's low-esteem self-...   \n","\n","                                                   text  \n","3120  <|endoftext|> Penny's bed in her apartment bre...  \n","42    <|endoftext|> After Han fires Caroline for dis...  \n","234   <|endoftext|> With Oliver reluctant to get ove...  \n","1343  <|endoftext|> Lane and Zach are getting marrie...  \n","376   <|endoftext|> When Jake and Amy have to stay a...  \n","...                                                 ...  \n","1317  <|endoftext|> Still smarting from her split wi...  \n","2283  <|endoftext|> Feeling frustrated and powerless...  \n","2004  <|endoftext|> Gloria's ex-husband, Javiér intr...  \n","3668  <|endoftext|> After almost forgetting that Bri...  \n","607   <|endoftext|> Cliff and Norm help Frasier's lo...  \n","\n","[4104 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8b14abfd-a385-4d51-9fe1-bd432d04dcbd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>PLOT</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3120</th>\n","      <td>The Gothowitz Deviation</td>\n","      <td>Penny's bed in her apartment breaks, forcing h...</td>\n","      <td>&lt;|endoftext|&gt; Penny's bed in her apartment bre...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>And the Big Hole</td>\n","      <td>After Han fires Caroline for disparaging the d...</td>\n","      <td>&lt;|endoftext|&gt; After Han fires Caroline for dis...</td>\n","    </tr>\n","    <tr>\n","      <th>234</th>\n","      <td>How Oliver Got His Groove Back</td>\n","      <td>With Oliver reluctant to get over Lindsey's di...</td>\n","      <td>&lt;|endoftext|&gt; With Oliver reluctant to get ove...</td>\n","    </tr>\n","    <tr>\n","      <th>1343</th>\n","      <td>I Get a Sidekick Out of You</td>\n","      <td>Lane and Zach are getting married and they hav...</td>\n","      <td>&lt;|endoftext|&gt; Lane and Zach are getting marrie...</td>\n","    </tr>\n","    <tr>\n","      <th>376</th>\n","      <td>The Road Trip</td>\n","      <td>When Jake and Amy have to stay at a B&amp;B in ups...</td>\n","      <td>&lt;|endoftext|&gt; When Jake and Amy have to stay a...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1317</th>\n","      <td>Jews and Chinese Food</td>\n","      <td>Still smarting from her split with Luke, Lorel...</td>\n","      <td>&lt;|endoftext|&gt; Still smarting from her split wi...</td>\n","    </tr>\n","    <tr>\n","      <th>2283</th>\n","      <td>Jerry's Painting</td>\n","      <td>Feeling frustrated and powerless because of he...</td>\n","      <td>&lt;|endoftext|&gt; Feeling frustrated and powerless...</td>\n","    </tr>\n","    <tr>\n","      <th>2004</th>\n","      <td>Flip Flop</td>\n","      <td>Gloria's ex-husband, Javiér introduces his new...</td>\n","      <td>&lt;|endoftext|&gt; Gloria's ex-husband, Javiér intr...</td>\n","    </tr>\n","    <tr>\n","      <th>3668</th>\n","      <td>The Show Must Go On</td>\n","      <td>After almost forgetting that Brick's middle-sc...</td>\n","      <td>&lt;|endoftext|&gt; After almost forgetting that Bri...</td>\n","    </tr>\n","    <tr>\n","      <th>607</th>\n","      <td>Don't Shoot...I'm Only the Psychiatrist</td>\n","      <td>Cliff and Norm help Frasier's low-esteem self-...</td>\n","      <td>&lt;|endoftext|&gt; Cliff and Norm help Frasier's lo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4104 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b14abfd-a385-4d51-9fe1-bd432d04dcbd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8b14abfd-a385-4d51-9fe1-bd432d04dcbd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8b14abfd-a385-4d51-9fe1-bd432d04dcbd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["#https://huggingface.co/docs/datasets/v1.2.0/loading_datasets.html#from-a-pandas-dataframe\n","# As reported in HuggingFace site, a dataset.Dataset can be loaded from a pandas dataframe.\n","# I will consider only the column TEXT since I have already concatenated each plot with the corrisponding title.\n","\n","train_dataset = Dataset.from_pandas(df_train[['text']])\n","val_dataset = Dataset.from_pandas(df_val[['text']])\n","test_dataset = Dataset.from_pandas(df_test[['text']])"],"metadata":{"id":"TnsPhLT8K7py"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__.padding\n","# With this function I tokenize each entry of the columun TEXT.\n","# As reported in HuggingFace, when the padding parameter of the tokenizer call is \n","# set to True, the tokenizer pads to the longest sequence in the batch.\n","# Since I pass the entire columun, the tokenizer automatically will pad to the maximum length possible.\n","\n","def tokenize_function(samples):\n","  return gpt_tokenizer(samples['text'], padding=True)"],"metadata":{"id":"T77nN7S4K7py"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mapping each set with the function tokenize_function and removing the column \n","# TEXT in which I no longer have an interest on, I obtain the final sets.\n","\n","gpt_train_dataset = train_dataset.map(\n","    tokenize_function,\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=['text']\n",")\n","\n","gpt_val_dataset = val_dataset.map(\n","    tokenize_function,\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=['text']\n",")\n","\n","gpt_test_dataset = test_dataset.map(\n","    tokenize_function,\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=['text']\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["926903256f124c9c9398b91e4da5c283","59085e7b150d49ccae4902d38924a718","10ef58f5b2f9432c8be386c41fb34866","d7b9a924d7dc4500827f66d61bd5e6c6","82cd6c3bac9f497b9ed75f5c49e71e5e","55a2ed3ea0374757a7fa2db85ff23b1a","3c707d33912f42a7a61ee02b509727cc","80d8caef21c14d2e8d36c5ad4d8b5872","90aa1067c9b248f6b00b38fe9fb6c125","9a505ad26a36443f932196310f414ab4","0c1210bca6184fcd89ed53bc2a1b43e3","0f41efaf15b44809bd2587155a30089e","1fb62f515d874fac8027c998db9b26f8","0c4c68fbfaaf4a498455aa295e9a4055","6d237799080e4082b25b53f49d0d16b3","4cc939ca5d8046e8b3cf8127811a0127","5d520df425f349ed90999d2f00a97a6d","2176844ca0d7483896d51418aec67ac1","040031e765b342bea8722bddaeb06827","b5b3b56aae16490da8b41c1a6d7d368b","6710646a9269438486387341785c0b28","cbc2978c9f704040b6562807918b15d5","cf017422631941a08b986d4976b7c662","5b8332de1aa84f58bbb748f0fff659a7","e8aeb05bbd054cfa9fe9fe33aa550b30","d8fe536a4dcb4702b964215053b80652","29018ef9dc6e4749b02134c5f68a9f31","d197e5f675954cc780e2a1b35b1f653f","b7dbf6279a584b8eb9f7f6108017bb4d","5771419be03a4366a268a46339a25e9f","2b8e4d60a69c4d51ac15e39cecba8d44","e254d713c5364450afb51f224144d405","dfa8ae6977784baf8e4646f8f0e2e490"],"height":17},"outputId":"c9a0b21a-d08f-4232-a4bd-8750d1a7b6c1","id":"UrBQs1nwK7py","executionInfo":{"status":"ok","timestamp":1686295655080,"user_tz":-120,"elapsed":8785,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4104 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"926903256f124c9c9398b91e4da5c283"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/228 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f41efaf15b44809bd2587155a30089e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/228 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf017422631941a08b986d4976b7c662"}},"metadata":{}}]},{"cell_type":"code","source":["gpt_train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3dhV4a8qsdO","executionInfo":{"status":"ok","timestamp":1686295655081,"user_tz":-120,"elapsed":17,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"4913fbec-449a-4ca0-965a-46a0dc7e04b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['__index_level_0__', 'input_ids', 'attention_mask'],\n","    num_rows: 4104\n","})"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["### Dataset for T5"],"metadata":{"id":"7vjFj900Ki-h"}},{"cell_type":"markdown","source":["Here I make the dataset compatible for the T5 model and thus I prepare the actual data that will be passed to the model. Note that here I start from df_train, df_val and df_test which were previously modified by adding the 'text' column, which is not important for the purposes of preparation anyway."],"metadata":{"id":"YbKtXrS9xJE5"}},{"cell_type":"code","source":["#https://huggingface.co/docs/datasets/v1.2.0/loading_datasets.html#from-a-pandas-dataframe\n","# As reported in HuggingFace site, a dataset.Dataset can be loaded from a pandas dataframe.\n","# I will consider both the columns PLOT and TITLE of each set.\n","\n","train_dataset = Dataset.from_pandas(df_train)\n","val_dataset = Dataset.from_pandas(df_val)\n","test_dataset = Dataset.from_pandas(df_test)"],"metadata":{"id":"BqOtCfMWO7-B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://huggingface.co/transformers/v3.1.0/model_doc/t5.html#training\n","# With this function I do the transformation to adjust the input data for the T5 model.\n","# For training, an input sequence and a target sequence are needed: in my case the input sequence is the tokenized plot \n","# and the target sequence is the tokenized title. As reported in HuggingFace, the target sequence corresponds to the labels.\n","\n","def preprocess_data(sample):\n","    \n","    model_inputs = t5_tokenizer(sample['PLOT'], max_length=MAX_SOURCE_LEN, padding=True, truncation=True)\n","\n","    with t5_tokenizer.as_target_tokenizer():\n","        labels = t5_tokenizer(sample['TITLE'], max_length=MAX_TARGET_LEN, padding=True, truncation=True)\n","\n","    # Replace all pad token ids in the labels with -100 to ignore padding in loss\n","    labels[\"input_ids\"] = [\n","        [(l if l != t5_tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n","    ]\n","\n","    model_inputs['labels'] = labels[\"input_ids\"]\n","\n","    return model_inputs"],"metadata":{"id":"EPXlKsZ3rnpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mapping each set with the function tokenize_function and \n","# removing the columns PLOT,TITLE and TEXT in which I no longer have an interest on, I obtain final sets.\n","\n","t5_train_dataset = train_dataset.map(\n","    preprocess_data,\n","    batched=True,\n","    remove_columns=['PLOT', 'TITLE', 'text'],\n","    num_proc=1\n",")\n","\n","t5_val_dataset = val_dataset.map(\n","    preprocess_data,\n","    batched=True,\n","    remove_columns=['PLOT', 'TITLE', 'text'],\n","    num_proc=1\n",")\n","\n","t5_test_dataset = test_dataset.map(\n","    preprocess_data,\n","    batched=True,\n","    remove_columns=['PLOT', 'TITLE', 'text'],\n","    num_proc=1\n",")"],"metadata":{"id":"xbI60WxzrpDQ","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["0de14e03ce45429e93a454f47ecc99c0","ddfbe19dd1be4ad6b6dae4495027e93a","e5c6c12c71d14fd6a86c26469d50014d","ceaab972127249a4ad854044f0112ec9","c90f10825ac64061a73db18bbfdcb157","b73a99b9f6fa419cae1a581d81fcd0d9","d07a444061154597945446d46f36afc8","1175bc0ae0854017a02be20ec5cf9f14","ecc07a88c4634307a9f68541f096603e","c594616cbbcc4a0f8ad81ac617efdd14","c45b139df2ed4c769a7636bae30758dc","72e06bad36c84d05bebc1fc20da80f90","2ea34d33d6684eac90a45b8d7a6753f0","5876e1eefc3a40b49cc5068204063146","9bb44881d71d4135b4492f58d4ab7e06","ee1fd3afd2344f21b1f860ddbe5aa4aa","4250d5dcafe948e8b0ee1bb789c400f4","6a15921bcc204f30b59f490c40ff2594","7e94dd0b0e914f23bc2314175ecf37a0","4b90cd4677db4656904170135bab6343","38fed8d39b86497dbd5e706a982e8283","e1d92bf0ff2b4204a7cde57cdce70385","c03608be16b04104bea749cb2b3fe6e1","5cf8a3fb0f6e47e289266a0063206233","9d06addd3e1749a2ba3b74710ffaf0b2","83274010e3d7430ebe119bd895a33b73","2e91bb113de64e569113f2b99c903ed6","c82c6f12dbcf4cd5a97e3c25055db050","16b43eaba81948208246b781fec762a6","4a13105150494d13ac6ac2afb72cf400","192a22e0b4544676bc97009cc375fcea","54bf5be21de94c93b710a949b18fb10a","d151bab5abed48b0838498e500268e56"],"height":72},"outputId":"baed50c6-a835-4a04-f0a2-6adf45e4f11a","executionInfo":{"status":"ok","timestamp":1686295657950,"user_tz":-120,"elapsed":2881,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4104 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de14e03ce45429e93a454f47ecc99c0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/228 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e06bad36c84d05bebc1fc20da80f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/228 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c03608be16b04104bea749cb2b3fe6e1"}},"metadata":{}}]},{"cell_type":"code","source":["t5_train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5X6xnZpqpxG","executionInfo":{"status":"ok","timestamp":1686295657951,"user_tz":-120,"elapsed":26,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"4218bb78-cbfa-4e23-d1ab-cce13993739c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4104\n","})"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["### Useful lists"],"metadata":{"id":"7d6dRCN2qWPL"}},{"cell_type":"markdown","source":["Here I create some lists that will be used later when new titles are generated in order to perform some checks."],"metadata":{"id":"lfC546EbzthW"}},{"cell_type":"code","source":["train_titles = list(df_train[\"TITLE\"])\n","  \n","val_titles = list(df_val[\"TITLE\"])\n","\n","test_titles = list(df_test[\"TITLE\"])\n","\n","test_plots_gpt = []\n","for p in df_test[\"PLOT\"]:\n","    test_plots_gpt.append(bos+p+title_tkn)\n","test_plots_t5 = list(df_test[\"PLOT\"])\n","test_plots = list(df_test[\"PLOT\"])"],"metadata":{"id":"jquML_vQpelF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and evaluation"],"metadata":{"id":"YbgwX4glw_EH"}},{"cell_type":"markdown","source":["## GPT-2"],"metadata":{"id":"99kJ2CuVdtHA"}},{"cell_type":"markdown","source":["Here's the code for the training of distil-GPT2 model. I use the HuggingFace Transformers API in order to get the data collator and trainer's objects."],"metadata":{"id":"dhS3gxYX3iWp"}},{"cell_type":"code","source":["# directly from https://huggingface.co/docs/evaluate/transformers_integrations#seq2seqtrainer\n","\n","# Define ROGUE metrics on evaluation data\n","metric = evaluate.load(\"rouge\")\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","\n","    # decode preds and labels\n","    labels = np.where(labels != -100, labels, gpt_tokenizer.pad_token_id)\n","    decoded_preds = gpt_tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    decoded_labels = gpt_tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # rougeLSum expects newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    return result"],"metadata":{"id":"BntOXW16hB1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorForLanguageModeling\n","# By instantiating the DataCollatorForLanguageModeling class, I get the object to form batches.\n","\n","if not already_trained:\n","  data_collator_gpt = DataCollatorForLanguageModeling(tokenizer=gpt_tokenizer,mlm=False)"],"metadata":{"id":"4QHDsvyhhB10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  model_path_gpt = \"/content/drive/MyDrive/NUANS/miniproject/model-distil-gpt2\"\n","  training_args_gpt = TrainingArguments(\n","      output_dir = model_path_gpt,          \n","      num_train_epochs = num_epochs,           \n","      per_device_train_batch_size = batch_size, \n","      per_device_eval_batch_size = batch_size, \n","      learning_rate=learning_rate,  \n","      warmup_steps = 200,               \n","      weight_decay = weight_decay,\n","      logging_dir = model_path_gpt,\n","      lr_scheduler_type = lr_scheduler_type,\n","      save_steps = 10000\n","  )"],"metadata":{"id":"DPz2wshJhB11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://huggingface.co/docs/transformers/main_classes/trainer\n","if not already_trained:\n","  trainer_gpt = Trainer(\n","    model=gpt_model,                         \n","    args=training_args_gpt,                  \n","    data_collator=data_collator_gpt,\n","    train_dataset=gpt_train_dataset,        \n","    eval_dataset=gpt_val_dataset,       \n","    compute_metrics=compute_metrics,\n","  )"],"metadata":{"id":"1FVTUulAhB12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  trainer_gpt.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"outputId":"d0255fd6-0ac5-4e9a-966b-9b9b38d940f9","id":"j541KDp2hB13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2565' max='2565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2565/2565 33:07, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>11.076800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.009200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.911200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.866800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.838700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2565, training_loss=5.30222536202295, metrics={'train_runtime': 1990.5897, 'train_samples_per_second': 10.309, 'train_steps_per_second': 1.289, 'total_flos': 2725145467158528.0, 'train_loss': 5.30222536202295, 'epoch': 5.0})"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["if not already_trained:\n","  trainer_gpt.save_model()\n","  gpt_tokenizer.save_pretrained(model_path_gpt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"84bd6a37-24b1-48b2-f356-eff1b54de99a","id":"8SN09dC5hB15"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/NUANS/miniproject/model-distil-gpt2/tokenizer_config.json',\n"," '/content/drive/MyDrive/NUANS/miniproject/model-distil-gpt2/special_tokens_map.json',\n"," '/content/drive/MyDrive/NUANS/miniproject/model-distil-gpt2/vocab.json',\n"," '/content/drive/MyDrive/NUANS/miniproject/model-distil-gpt2/merges.txt',\n"," '/content/drive/MyDrive/NUANS/miniproject/model-distil-gpt2/added_tokens.json')"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["### Problems with GPU"],"metadata":{"id":"hqXYjtOnhB16"}},{"cell_type":"markdown","source":["Here I have reported both the attempt to calculate the metric during the training phase using the validation set and the attempt of the evaluation of the model just trained. Both the trials end with \"CUDA out of memory\" and thus I decide to exclude these steps."],"metadata":{"id":"zD9pVZpC2qjs"}},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"qM6EXVubhB16"}},{"cell_type":"code","source":["# training_args_gpt = TrainingArguments(\n","#     output_dir = model_path_gpt,          \n","#     num_train_epochs = num_epochs,           \n","#     per_device_train_batch_size = 5, \n","#     per_device_eval_batch_size = 5,\n","#     evaluation_strategy =\"steps\",\n","#     eval_steps = 50,   \n","#     warmup_steps = 200,               \n","#     weight_decay = 0.01,\n","#     logging_dir = model_path_gpt,\n","#     save_steps = 10000\n","# )\n","\n","# trainer_gpt = Trainer(\n","#     model=gpt_model,                         \n","#     args=training_args_gpt,                  \n","#     data_collator=data_collator_gpt,\n","#     train_dataset=gpt_train_dataset,        \n","#     eval_dataset=gpt_val_dataset,       \n","#     compute_metrics=compute_metrics,\n","# )"],"metadata":{"id":"9GtlvC7mhB16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"73276ba9-a358-4ed6-c17e-7e796c9fd93e","executionInfo":{"status":"error","timestamp":1684855300418,"user_tz":-120,"elapsed":27570,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"id":"kYuegn50hB17"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='51' max='1642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  51/1642 00:22 < 12:14, 2.17 it/s, Epoch 0.06/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='11' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11/46 00:02 < 00:07, 4.73 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1664\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1664 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1666 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1667 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2019\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2016 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.state.epoch = epoch + (step + \u001b[94m1\u001b[0m + steps_skipped) / steps_in_epo  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2017 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_end(args, \u001b[96mself\u001b[0m.state, \u001b[96ms\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2018 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2019 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2020 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2021 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_substep_end(args, \u001b[96mself\u001b[0m.state  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2022 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2300\u001b[0m in \u001b[92m_maybe_log_save_evaluate\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2297 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2298 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmetrics.update(dataset_metrics)                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2299 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2300 \u001b[2m│   │   │   │   \u001b[0mmetrics = \u001b[96mself\u001b[0m.evaluate(ignore_keys=ignore_keys_for_eval)                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2301 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._report_to_hp_search(trial, \u001b[96mself\u001b[0m.state.global_step, metrics)             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2302 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2303 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Run delayed LR scheduler now that metrics are populated\u001b[0m                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3029\u001b[0m in \u001b[92mevaluate\u001b[0m                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3026 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3027 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3028 \u001b[0m\u001b[2m│   │   \u001b[0meval_loop = \u001b[96mself\u001b[0m.prediction_loop \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.use_legacy_prediction_loop \u001b[94melse\u001b[0m \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3029 \u001b[2m│   │   \u001b[0moutput = eval_loop(                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3030 \u001b[0m\u001b[2m│   │   │   \u001b[0meval_dataloader,                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3031 \u001b[0m\u001b[2m│   │   │   \u001b[0mdescription=\u001b[33m\"\u001b[0m\u001b[33mEvaluation\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3032 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# No point gathering the predictions if there are no metrics, otherwise we d\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3235\u001b[0m in \u001b[92mevaluation_loop\u001b[0m          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3232 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.preprocess_logits_for_metrics \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3233 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlogits = \u001b[96mself\u001b[0m.preprocess_logits_for_metrics(logits, labels)           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3234 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogits = \u001b[96mself\u001b[0m._nested_gather(logits)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3235 \u001b[2m│   │   │   │   \u001b[0mpreds_host = logits \u001b[94mif\u001b[0m preds_host \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m nested_concat(preds_host,  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3236 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m labels \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3237 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlabels = \u001b[96mself\u001b[0m._nested_gather(labels)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3238 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlabels_host = labels \u001b[94mif\u001b[0m labels_host \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m nested_concat(labels_ho  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer_pt_utils.py\u001b[0m:\u001b[94m116\u001b[0m in \u001b[92mnested_concat\u001b[0m    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(tensors, (\u001b[96mlist\u001b[0m, \u001b[96mtuple\u001b[0m)):                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mtype\u001b[0m(tensors)(nested_concat(t, n, padding_index=padding_index) \u001b[94mfor\u001b[0m t, n \u001b[95mi\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 115 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(tensors, torch.Tensor):                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 116 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_ind  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(tensors, Mapping):                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 118 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mtype\u001b[0m(tensors)(                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 119 \u001b[0m\u001b[2m│   │   │   \u001b[0m{k: nested_concat(t, new_tensors[k], padding_index=padding_index) \u001b[94mfor\u001b[0m k, t \u001b[95mi\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer_pt_utils.py\u001b[0m:\u001b[94m75\u001b[0m in                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mtorch_pad_and_concatenate\u001b[0m                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m│   \u001b[0mtensor2 = atleast_1d(tensor2)                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  74 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(tensor1.shape) == \u001b[94m1\u001b[0m \u001b[95mor\u001b[0m tensor1.shape[\u001b[94m1\u001b[0m] == tensor2.shape[\u001b[94m1\u001b[0m]:                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  75 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.cat((tensor1, tensor2), dim=\u001b[94m0\u001b[0m)                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  76 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  77 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Let's figure out the new shape\u001b[0m                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  78 \u001b[0m\u001b[2m│   \u001b[0mnew_shape = (tensor1.shape[\u001b[94m0\u001b[0m] + tensor2.shape[\u001b[94m0\u001b[0m], \u001b[96mmax\u001b[0m(tensor1.shape[\u001b[94m1\u001b[0m], tensor2.shap  \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m4.89\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.75\u001b[0m GiB total capacity; \u001b[1;36m6.45\u001b[0m GiB already\n","allocated; \u001b[1;36m3.26\u001b[0m GiB free; \u001b[1;36m10.71\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n","setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2019</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2016 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.epoch = epoch + (step + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + steps_skipped) / steps_in_epo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2017 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">s</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2018 │   │   │   │   │   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2019 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2020 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2021 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_substep_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2022 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2300</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_log_save_evaluate</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2297 │   │   │   │   │   </span>)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2298 │   │   │   │   │   </span>metrics.update(dataset_metrics)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2299 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2300 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.evaluate(ignore_keys=ignore_keys_for_eval)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2301 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._report_to_hp_search(trial, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.global_step, metrics)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2302 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2303 │   │   │   # Run delayed LR scheduler now that metrics are populated</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3029</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3026 │   │   </span>start_time = time.time()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3028 │   │   </span>eval_loop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.use_legacy_prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3029 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = eval_loop(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3030 │   │   │   </span>eval_dataloader,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3031 │   │   │   </span>description=<span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluation\"</span>,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3032 │   │   │   # No point gathering the predictions if there are no metrics, otherwise we d</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3235</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation_loop</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3232 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess_logits_for_metrics <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3233 │   │   │   │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess_logits_for_metrics(logits, labels)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3234 │   │   │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._nested_gather(logits)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3235 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>preds_host = logits <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> preds_host <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> nested_concat(preds_host,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3236 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> labels <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3237 │   │   │   │   </span>labels = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._nested_gather(labels)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3238 │   │   │   │   </span>labels_host = labels <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> labels_host <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> nested_concat(labels_ho  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer_pt_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">nested_concat</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensors, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>)):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(tensors)(nested_concat(t, n, padding_index=padding_index) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t, n <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">i</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 115 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensors, torch.Tensor):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 116 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_ind  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensors, Mapping):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 118 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(tensors)(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 119 │   │   │   </span>{k: nested_concat(t, new_tensors[k], padding_index=padding_index) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">i</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer_pt_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">torch_pad_and_concatenate</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 │   </span>tensor2 = atleast_1d(tensor2)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  74 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(tensor1.shape) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> tensor1.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] == tensor2.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]:                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  75 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.cat((tensor1, tensor2), dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  76 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  77 │   # Let's figure out the new shape</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  78 │   </span>new_shape = (tensor1.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] + tensor2.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">max</span>(tensor1.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], tensor2.shap  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.89</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.45</span> GiB already\n","allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.26</span> GiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.71</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory try \n","setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["#### Evaluation"],"metadata":{"id":"qduTsgmchB17"}},{"cell_type":"code","source":["# trainer_gpt.evaluate(eval_dataset=gpt_test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":815},"outputId":"a0e8429c-e7b4-4679-c597-12629a0bc917","id":"QnYBu9nMhB18"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 9/29 00:02 < 00:05, 3.91 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3029\u001b[0m in \u001b[92mevaluate\u001b[0m                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3026 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3027 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3028 \u001b[0m\u001b[2m│   │   \u001b[0meval_loop = \u001b[96mself\u001b[0m.prediction_loop \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.use_legacy_prediction_loop \u001b[94melse\u001b[0m \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3029 \u001b[2m│   │   \u001b[0moutput = eval_loop(                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3030 \u001b[0m\u001b[2m│   │   │   \u001b[0meval_dataloader,                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3031 \u001b[0m\u001b[2m│   │   │   \u001b[0mdescription=\u001b[33m\"\u001b[0m\u001b[33mEvaluation\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3032 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# No point gathering the predictions if there are no metrics, otherwise we d\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3235\u001b[0m in \u001b[92mevaluation_loop\u001b[0m          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3232 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.preprocess_logits_for_metrics \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3233 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlogits = \u001b[96mself\u001b[0m.preprocess_logits_for_metrics(logits, labels)           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3234 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogits = \u001b[96mself\u001b[0m._nested_gather(logits)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3235 \u001b[2m│   │   │   │   \u001b[0mpreds_host = logits \u001b[94mif\u001b[0m preds_host \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m nested_concat(preds_host,  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3236 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m labels \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3237 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlabels = \u001b[96mself\u001b[0m._nested_gather(labels)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3238 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlabels_host = labels \u001b[94mif\u001b[0m labels_host \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m nested_concat(labels_ho  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer_pt_utils.py\u001b[0m:\u001b[94m116\u001b[0m in \u001b[92mnested_concat\u001b[0m    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(tensors, (\u001b[96mlist\u001b[0m, \u001b[96mtuple\u001b[0m)):                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mtype\u001b[0m(tensors)(nested_concat(t, n, padding_index=padding_index) \u001b[94mfor\u001b[0m t, n \u001b[95mi\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 115 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(tensors, torch.Tensor):                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 116 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_ind  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(tensors, Mapping):                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 118 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mtype\u001b[0m(tensors)(                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 119 \u001b[0m\u001b[2m│   │   │   \u001b[0m{k: nested_concat(t, new_tensors[k], padding_index=padding_index) \u001b[94mfor\u001b[0m k, t \u001b[95mi\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer_pt_utils.py\u001b[0m:\u001b[94m75\u001b[0m in                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mtorch_pad_and_concatenate\u001b[0m                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m│   \u001b[0mtensor2 = atleast_1d(tensor2)                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  74 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(tensor1.shape) == \u001b[94m1\u001b[0m \u001b[95mor\u001b[0m tensor1.shape[\u001b[94m1\u001b[0m] == tensor2.shape[\u001b[94m1\u001b[0m]:                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  75 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.cat((tensor1, tensor2), dim=\u001b[94m0\u001b[0m)                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  76 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  77 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Let's figure out the new shape\u001b[0m                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  78 \u001b[0m\u001b[2m│   \u001b[0mnew_shape = (tensor1.shape[\u001b[94m0\u001b[0m] + tensor2.shape[\u001b[94m0\u001b[0m], \u001b[96mmax\u001b[0m(tensor1.shape[\u001b[94m1\u001b[0m], tensor2.shap  \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m5.17\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.75\u001b[0m GiB total capacity; \u001b[1;36m6.11\u001b[0m GiB already\n","allocated; \u001b[1;36m3.13\u001b[0m GiB free; \u001b[1;36m10.84\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n","setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3029</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3026 │   │   </span>start_time = time.time()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3028 │   │   </span>eval_loop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.use_legacy_prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3029 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = eval_loop(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3030 │   │   │   </span>eval_dataloader,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3031 │   │   │   </span>description=<span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluation\"</span>,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3032 │   │   │   # No point gathering the predictions if there are no metrics, otherwise we d</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3235</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation_loop</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3232 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess_logits_for_metrics <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3233 │   │   │   │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess_logits_for_metrics(logits, labels)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3234 │   │   │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._nested_gather(logits)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3235 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>preds_host = logits <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> preds_host <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> nested_concat(preds_host,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3236 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> labels <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3237 │   │   │   │   </span>labels = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._nested_gather(labels)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3238 │   │   │   │   </span>labels_host = labels <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> labels_host <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> nested_concat(labels_ho  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer_pt_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">nested_concat</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensors, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>)):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(tensors)(nested_concat(t, n, padding_index=padding_index) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t, n <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">i</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 115 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensors, torch.Tensor):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 116 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_ind  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensors, Mapping):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 118 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(tensors)(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 119 │   │   │   </span>{k: nested_concat(t, new_tensors[k], padding_index=padding_index) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">i</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer_pt_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">torch_pad_and_concatenate</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 │   </span>tensor2 = atleast_1d(tensor2)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  74 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(tensor1.shape) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> tensor1.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] == tensor2.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]:                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  75 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.cat((tensor1, tensor2), dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  76 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  77 │   # Let's figure out the new shape</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  78 │   </span>new_shape = (tensor1.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] + tensor2.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">max</span>(tensor1.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], tensor2.shap  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.17</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.11</span> GiB already\n","allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.13</span> GiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.84</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory try \n","setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"xNPxa9TXdwYy"}},{"cell_type":"markdown","source":["Here's the code for the training of T5 model. I use the HuggingFace Transformers API in order to get the data collator and the trainer's objects."],"metadata":{"id":"EJsLe3kf37fP"}},{"cell_type":"code","source":["# directly from https://huggingface.co/docs/evaluate/transformers_integrations#seq2seqtrainer\n","\n","# Define ROGUE metrics on evaluation data\n","metric = evaluate.load(\"rouge\")\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","\n","    # decode preds and labels\n","    labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n","    decoded_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    decoded_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # rougeLSum expects newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    return result"],"metadata":{"id":"CeyZ-CWqsn7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  data_collator_t5 = DataCollatorForSeq2Seq(t5_tokenizer, model=t5_model)"],"metadata":{"id":"vfGeZFg7sqBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  model_path_t5 = '/content/drive/MyDrive/NUANS/miniproject/model-t5-base'\n","  training_args_t5 = Seq2SeqTrainingArguments(\n","      output_dir=model_path_t5,\n","      evaluation_strategy=\"steps\",\n","      eval_steps=eval_every,\n","      learning_rate=learning_rate,\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      weight_decay=weight_decay,\n","      num_train_epochs=num_epochs,\n","      predict_with_generate=True,\n","      logging_steps=log_every,\n","      group_by_length=True,\n","      lr_scheduler_type=lr_scheduler_type,\n","      resume_from_checkpoint=True,\n","  )"],"metadata":{"id":"Xv6p1dz7yKnF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  t5_trainer = Seq2SeqTrainer(\n","    t5_model,\n","    training_args_t5,\n","    train_dataset=t5_train_dataset,\n","    eval_dataset=t5_val_dataset,\n","    data_collator=data_collator_t5,\n","    tokenizer=t5_tokenizer,\n","    compute_metrics=compute_metrics,\n","  )"],"metadata":{"id":"4mCGlDmrsqjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not already_trained:\n","  t5_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qcWWuvkSss6V","outputId":"653cc7b3-e31e-4cce-edb4-051813475f5c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2565' max='2565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2565/2565 1:17:49, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>4.590200</td>\n","      <td>4.252470</td>\n","      <td>0.098718</td>\n","      <td>0.025833</td>\n","      <td>0.097681</td>\n","      <td>0.096961</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.288200</td>\n","      <td>3.899623</td>\n","      <td>0.116279</td>\n","      <td>0.021254</td>\n","      <td>0.115807</td>\n","      <td>0.116566</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.077000</td>\n","      <td>3.770224</td>\n","      <td>0.140052</td>\n","      <td>0.024050</td>\n","      <td>0.138746</td>\n","      <td>0.138873</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>3.837400</td>\n","      <td>3.681719</td>\n","      <td>0.167929</td>\n","      <td>0.030702</td>\n","      <td>0.167288</td>\n","      <td>0.167396</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>3.859400</td>\n","      <td>3.622344</td>\n","      <td>0.170478</td>\n","      <td>0.036550</td>\n","      <td>0.169934</td>\n","      <td>0.170229</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>3.889300</td>\n","      <td>3.573097</td>\n","      <td>0.181129</td>\n","      <td>0.039975</td>\n","      <td>0.179932</td>\n","      <td>0.179590</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>3.898300</td>\n","      <td>3.536280</td>\n","      <td>0.182918</td>\n","      <td>0.039975</td>\n","      <td>0.180712</td>\n","      <td>0.181438</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>3.679400</td>\n","      <td>3.506391</td>\n","      <td>0.183681</td>\n","      <td>0.037907</td>\n","      <td>0.181870</td>\n","      <td>0.182303</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>3.700500</td>\n","      <td>3.486960</td>\n","      <td>0.183560</td>\n","      <td>0.036550</td>\n","      <td>0.181257</td>\n","      <td>0.182348</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>3.653700</td>\n","      <td>3.460644</td>\n","      <td>0.189701</td>\n","      <td>0.046230</td>\n","      <td>0.187469</td>\n","      <td>0.188570</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>3.578800</td>\n","      <td>3.441700</td>\n","      <td>0.193302</td>\n","      <td>0.045635</td>\n","      <td>0.190930</td>\n","      <td>0.191507</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>3.611900</td>\n","      <td>3.427601</td>\n","      <td>0.196027</td>\n","      <td>0.050146</td>\n","      <td>0.193165</td>\n","      <td>0.194070</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>3.483800</td>\n","      <td>3.416594</td>\n","      <td>0.196342</td>\n","      <td>0.053185</td>\n","      <td>0.193357</td>\n","      <td>0.194632</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>3.586500</td>\n","      <td>3.403025</td>\n","      <td>0.196091</td>\n","      <td>0.050146</td>\n","      <td>0.192633</td>\n","      <td>0.193749</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>3.575500</td>\n","      <td>3.386159</td>\n","      <td>0.194872</td>\n","      <td>0.056287</td>\n","      <td>0.191627</td>\n","      <td>0.192473</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>3.388100</td>\n","      <td>3.378422</td>\n","      <td>0.194819</td>\n","      <td>0.058187</td>\n","      <td>0.191937</td>\n","      <td>0.192701</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>3.518600</td>\n","      <td>3.370945</td>\n","      <td>0.193768</td>\n","      <td>0.058187</td>\n","      <td>0.191349</td>\n","      <td>0.192036</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>3.637100</td>\n","      <td>3.363302</td>\n","      <td>0.194975</td>\n","      <td>0.055368</td>\n","      <td>0.192317</td>\n","      <td>0.193310</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>3.688000</td>\n","      <td>3.349571</td>\n","      <td>0.199589</td>\n","      <td>0.060714</td>\n","      <td>0.196657</td>\n","      <td>0.197876</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.495500</td>\n","      <td>3.344072</td>\n","      <td>0.200752</td>\n","      <td>0.061842</td>\n","      <td>0.197623</td>\n","      <td>0.198535</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>3.537900</td>\n","      <td>3.341284</td>\n","      <td>0.200838</td>\n","      <td>0.066082</td>\n","      <td>0.197512</td>\n","      <td>0.198814</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>3.506200</td>\n","      <td>3.338795</td>\n","      <td>0.195864</td>\n","      <td>0.064662</td>\n","      <td>0.192689</td>\n","      <td>0.194005</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>3.566600</td>\n","      <td>3.329468</td>\n","      <td>0.202984</td>\n","      <td>0.067982</td>\n","      <td>0.199097</td>\n","      <td>0.201036</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>3.436900</td>\n","      <td>3.324751</td>\n","      <td>0.203683</td>\n","      <td>0.067022</td>\n","      <td>0.200713</td>\n","      <td>0.201863</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>3.463100</td>\n","      <td>3.316915</td>\n","      <td>0.205399</td>\n","      <td>0.069309</td>\n","      <td>0.202031</td>\n","      <td>0.203115</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>3.514700</td>\n","      <td>3.314004</td>\n","      <td>0.202774</td>\n","      <td>0.069069</td>\n","      <td>0.198654</td>\n","      <td>0.199684</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>3.299400</td>\n","      <td>3.307903</td>\n","      <td>0.199560</td>\n","      <td>0.071435</td>\n","      <td>0.195811</td>\n","      <td>0.196980</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>3.299200</td>\n","      <td>3.305859</td>\n","      <td>0.198145</td>\n","      <td>0.072742</td>\n","      <td>0.194125</td>\n","      <td>0.195036</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>3.513800</td>\n","      <td>3.302358</td>\n","      <td>0.202935</td>\n","      <td>0.074387</td>\n","      <td>0.199646</td>\n","      <td>0.201503</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.311600</td>\n","      <td>3.298873</td>\n","      <td>0.203173</td>\n","      <td>0.076752</td>\n","      <td>0.199678</td>\n","      <td>0.201449</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>3.511600</td>\n","      <td>3.293872</td>\n","      <td>0.202389</td>\n","      <td>0.077924</td>\n","      <td>0.198989</td>\n","      <td>0.199576</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>3.343100</td>\n","      <td>3.291189</td>\n","      <td>0.201847</td>\n","      <td>0.077924</td>\n","      <td>0.197566</td>\n","      <td>0.198748</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>3.407000</td>\n","      <td>3.287915</td>\n","      <td>0.201491</td>\n","      <td>0.077924</td>\n","      <td>0.197232</td>\n","      <td>0.198498</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>3.311300</td>\n","      <td>3.286323</td>\n","      <td>0.199310</td>\n","      <td>0.078026</td>\n","      <td>0.197167</td>\n","      <td>0.198144</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>3.458200</td>\n","      <td>3.283294</td>\n","      <td>0.199011</td>\n","      <td>0.077924</td>\n","      <td>0.195234</td>\n","      <td>0.196941</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>3.314000</td>\n","      <td>3.282829</td>\n","      <td>0.200805</td>\n","      <td>0.078472</td>\n","      <td>0.198063</td>\n","      <td>0.199276</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>3.382300</td>\n","      <td>3.280342</td>\n","      <td>0.200208</td>\n","      <td>0.079885</td>\n","      <td>0.198894</td>\n","      <td>0.199554</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>3.358900</td>\n","      <td>3.278446</td>\n","      <td>0.198063</td>\n","      <td>0.080000</td>\n","      <td>0.196045</td>\n","      <td>0.196610</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>3.451400</td>\n","      <td>3.277847</td>\n","      <td>0.202278</td>\n","      <td>0.080414</td>\n","      <td>0.201000</td>\n","      <td>0.201469</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.491400</td>\n","      <td>3.275777</td>\n","      <td>0.196368</td>\n","      <td>0.080686</td>\n","      <td>0.194807</td>\n","      <td>0.195830</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>3.394700</td>\n","      <td>3.273710</td>\n","      <td>0.194413</td>\n","      <td>0.080414</td>\n","      <td>0.192738</td>\n","      <td>0.194341</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>3.312000</td>\n","      <td>3.271768</td>\n","      <td>0.194164</td>\n","      <td>0.080284</td>\n","      <td>0.192451</td>\n","      <td>0.193834</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>3.367300</td>\n","      <td>3.270489</td>\n","      <td>0.194164</td>\n","      <td>0.080284</td>\n","      <td>0.192451</td>\n","      <td>0.193834</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>3.316700</td>\n","      <td>3.269804</td>\n","      <td>0.193308</td>\n","      <td>0.080414</td>\n","      <td>0.191582</td>\n","      <td>0.193218</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>3.343600</td>\n","      <td>3.269049</td>\n","      <td>0.191212</td>\n","      <td>0.076925</td>\n","      <td>0.189877</td>\n","      <td>0.190081</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>3.382600</td>\n","      <td>3.268533</td>\n","      <td>0.191212</td>\n","      <td>0.076925</td>\n","      <td>0.189877</td>\n","      <td>0.190081</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>3.314200</td>\n","      <td>3.268049</td>\n","      <td>0.194164</td>\n","      <td>0.080284</td>\n","      <td>0.192451</td>\n","      <td>0.193834</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>3.495600</td>\n","      <td>3.267963</td>\n","      <td>0.189752</td>\n","      <td>0.076925</td>\n","      <td>0.188385</td>\n","      <td>0.189090</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>3.338700</td>\n","      <td>3.267532</td>\n","      <td>0.191453</td>\n","      <td>0.076925</td>\n","      <td>0.190123</td>\n","      <td>0.190715</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.329600</td>\n","      <td>3.267329</td>\n","      <td>0.189752</td>\n","      <td>0.076925</td>\n","      <td>0.188385</td>\n","      <td>0.189090</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>3.359100</td>\n","      <td>3.267304</td>\n","      <td>0.189752</td>\n","      <td>0.076925</td>\n","      <td>0.188385</td>\n","      <td>0.189090</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["CPU times: user 58min 12s, sys: 12min 4s, total: 1h 10min 16s\n","Wall time: 1h 17min 53s\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2565, training_loss=3.537028021561472, metrics={'train_runtime': 4671.1529, 'train_samples_per_second': 4.393, 'train_steps_per_second': 0.549, 'total_flos': 1.300563736326144e+16, 'train_loss': 3.537028021561472, 'epoch': 5.0})"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{"id":"WU5KEK_VZ3a2"}},{"cell_type":"code","source":["if not already_trained:\n","  t5_trainer.evaluate(eval_dataset=t5_test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"yD_0UOGKsw9k","outputId":"c5d2f597-61b5-4537-bc97-cfa20c362bc9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [29/29 00:19]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["CPU times: user 19.7 s, sys: 421 ms, total: 20.1 s\n","Wall time: 20.5 s\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 3.1731691360473633,\n"," 'eval_rouge1': 0.18764824356929616,\n"," 'eval_rouge2': 0.06558235867446394,\n"," 'eval_rougeL': 0.18803508869298338,\n"," 'eval_rougeLsum': 0.18787361517624673,\n"," 'eval_runtime': 20.5103,\n"," 'eval_samples_per_second': 11.116,\n"," 'eval_steps_per_second': 1.414,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["if not already_trained:\n","  model_path_t5 = f\"{model_path_t5}/checkpoint-2500\""],"metadata":{"id":"heNDI3cLLRAq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generation of new titles"],"metadata":{"id":"qyjy16yqZ5nz"}},{"cell_type":"code","source":["if torch.cuda.is_available():  \n","    dev = \"cuda:0\" \n","else:  \n","    dev = \"cpu\"  \n","device = torch.device(dev)"],"metadata":{"id":"xpnrSPuaYGxW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GPT-2"],"metadata":{"id":"GDlQUDEZgVJo"}},{"cell_type":"markdown","source":["Since the generate method returns the input concatenated to the generated response, I need to set the max_length parameter corresponding to the length of the input plot + max_new_tokens. In this case I have decided that titles must have a maximum length equal to 6."],"metadata":{"id":"uICZ8SGf6vCb"}},{"cell_type":"code","source":["def title_generation(model, tokenizer, input_text, device, beam_search=True):\n","    text_ids = tokenizer.encode(input_text, return_tensors = 'pt')\n","    text_ids = text_ids.to(device)\n","    model = model.to(device)\n","\n","    if beam_search:\n","      new_title = model.generate(\n","        text_ids,\n","        max_length= text_ids.shape[1]+6,\n","        temperature=temperature, \n","        num_beams=num_beams, \n","        early_stopping=True\n","      )\n","      \n","    # The alternative to beam search is Top-K, Top-P sampling\n","    if not beam_search:\n","      new_title = model.generate(\n","          text_ids, \n","          max_length = text_ids.shape[1]+6,  \n","          no_repeat_ngram_size = no_repeat_ngram_size,\n","          repetition_penalty = repetition_penalty,\n","          top_p = top_p,\n","          temperature = temperature,\n","          do_sample = True,\n","          top_k = top_k,\n","          early_stopping = True\n","      )\n","\n","    title = tokenizer.decode(new_title[0], skip_special_tokens=True)\n","    return title"],"metadata":{"id":"uCm1bSWsk5v4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt_model = GPT2LMHeadModel.from_pretrained(model_path_gpt)\n","gpt_tokenizer = GPT2Tokenizer.from_pretrained(model_path_gpt)\n","\n","bos = gpt_tokenizer.bos_token\n","eos = gpt_tokenizer.eos_token\n","title_tkn = gpt_tokenizer.sep_token"],"metadata":{"id":"ZNLyTjmibPr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt_titles = []\n","\n","for plot in test_plots_gpt:\n","\n","    title = title_generation(gpt_model, gpt_tokenizer, plot, device, beam_search=False)\n","    \n","    # Actually \"title\" is the input sequence concatenated to the generated title.\n","    # I need to separate the input sequence to focus on the title.\n","    plot_length = len(plot[len(bos):-len(title_tkn)])\n","    gpt_titles.append(title[plot_length:])"],"metadata":{"id":"2__7Hms3U3D_","executionInfo":{"status":"ok","timestamp":1686295676052,"user_tz":-120,"elapsed":12812,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ae3b2d3-842e-44dd-c18b-c38b1c264479"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print(len(test_plots_gpt))\n","print(len(gpt_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8Tl2yzF3yU3","executionInfo":{"status":"ok","timestamp":1686295676053,"user_tz":-120,"elapsed":29,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"876f609f-3abb-40f0-9c79-d420c2d3f7b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["228\n","228\n"]}]},{"cell_type":"code","source":["# Printing the first 20 samples\n","for plot, titles in zip(test_plots[:20],zip(test_titles[:20], gpt_titles[:20])):\n","    print(f\"Plot: {plot}\")\n","    print(f\"Original title: {titles[0]}\")\n","    print(f\"Generated title: {titles[1]}\")\n","    print() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTocd7xu2q_n","executionInfo":{"status":"ok","timestamp":1686295676053,"user_tz":-120,"elapsed":9,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"32a32355-5377-45e7-a24c-f760022e573f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Plot: One year after the airing of the documentary, past and present employees of Dunder Mifflin gather for Dwight and Angela's wedding. Dwight initially chooses Jim to be his best man, but Michael Scott shows up and takes his place. Finally, everyone comes together for a final round of interviews, during which Erin reunites with her biological parents and everyone is brought to tears. \n","Original title: Finale\n","Generated title: he Interview\n","\n","Plot: Dangle (and an unwilling Williams) take time to connect with his black half-brother and half-sister from his father's other family in Chicago.\n","Original title: Back in Black\n","Generated title: The Great Race\n","\n","Plot: Dangle's ex-wife's husband proposes to him. A naked Wiegel gets stuck in a giant cake and goes into labor. Dangle holds his wedding at the hospital when Garcia bursts in and declares his love for Dangle's fiancee. Wiegel tells Dangle that she knows who her child's father is.\n","Original title: Dangle's Wedding (Part 1)\n","Generated title: The Cake\n","\n","Plot: Mindy is tired of Annette hovering around her relationship with Danny and decides to set her up on a date with Dr. Ledreau, an older practitioner from their building. Jeremy also has his eyes on this soon-to-be-retired doctor, as he is hoping for the practice to receive his patient list. Saddened by his breakup with Tamra, Morgan is convinced by Peter to set up an online dating profile.\n","Original title: How to Lose a Mom in Ten Days\n","Generated title: Animate Minds\n","\n","Plot: Joey falls for Phoebe's identical twin sister, Ursula, making Phoebe feel neglected. Meanwhile, Chandler finds himself between a rock and a hard place when he has to fire an employee he is attracted to. Ross has doubts about parenthood when he attends Lamaze classes with Carol and Susan. Meanwhile, Monica is unable to fix her TV after Marcel puts it on the \"SAP\" function to Spanish. After weeks of procrastinating, Rachel finally takes down the Christmas lights on their balcony, only to fall off and sprain her ankle.At the hospital, Rachel, who has no health insurance, convinces Monica to trade identities with her so she can use Monica's coverage. The women meet two attractive doctors and arrange a date, requiring them to maintain their switched identities. Ursula dumps Joey without actually telling him, so Phoebe pretends to be her so Joey will finally know. Ross doubts his ability to be a father. After Marcel swallows \"Scrabble\" tiles and has a trip to the hospital, Ross takes care of him, giving him confidence to be a good father.\n","Original title: The One with Two Parts\n","Generated title: The Two Wants You To\n","\n","Plot: When April accidentally scheduled all of Ron's meetings for March 31 thinking that March only had 30 days, Ron has ninety-three meetings scheduled all for one day and enlists the help of everyone in the Parks department to get through them. At one of the meetings, Leslie discovers that Jessica Wicks, former Miss Pawnee and wife of Nick Newport, is planning on making alterations to a Pawnee mansion and she recruits Tom to help her stop it.\n","Original title: 94 Meetings\n","Generated title: The One With Three Days?\n","\n","Plot: A year after Halloween Part III, Jake, Amy and Holt agree on having another heist to prove once and for all who is in fact the true detective/genius in the 99. Holt begins to thwart Jake plans by choosing Charles for his team, while Rosa fully commits to Amy's antics. Meanwhile, Hitchcock and Scully are given the task to watch Terry, as the crew suspects he has something up his sleeve when he refuses to be a part of the heist. Gina proves who the \"Ultimate Human/Genius\" is.\n","Original title: Halloween IV\n","Generated title: The Best Detective\n","\n","Plot: While drunk, Robert shuts down Dunder Mifflin's Binghamton branch. Andy prepares to make his comeback by temporarily forming his own rival paper company. Jim and Dwight work together to defeat a rival Dunder Mifflin salesman who wants the Binghamton branch's clients.\n","Original title: Turf War\n","Generated title: Bingamonts\n","\n","Plot: Joey proves to be a sore loser after being nominated for a \"Soapie\" award. When he accepts an award from a different category on behalf of a co-star, he is unwilling to hand it over. However, he later keeps the award anyway when the actress who has won it considers it insignificant. Meanwhile, a male student in Ross’s class angles for a higher test grade by claiming that he loves Ross. Another student reveals that the guy is actually straight, and has used the same ploy on other professors. Ross then gives the student a failing grade, but ends up giving him a \"C\" after some of Ross's colleagues overhear a conversation which sounds like Ross and the student dated.\n","Original title: The One with Joey's Award\n","Generated title: Soapsies\n","\n","Plot: Jake's chaotic half-sister, Katie, comes to visit him and Amy for a couple days after a rough break-up. When she considers moving to New York to live with them, the two try to figure out a way to get her to return to Dallas. Terry injures himself after performing yoga with Charles and gets stuck in Hitchcock and Scully’s nap room. Gina tries to set Rosa up on a date.\n","Original title: DFW\n","Generated title: My Sister\n","\n","Plot: Oscar arranges a happy hour with the warehouse staff so he can flirt with Matt. Pam is excited to see the staff and brings a date for Michael, but he ends up connecting with the bar manager, Donna, instead. Meanwhile, Andy and Erin announce their relationship. Dwight meets Isabel and drops Angela to hang out with Isabel, making Angela jealous. When Dwight tells Angela to forget about the pre-natal contract, she confronts him in front of Isabel.\n","Original title: Happy Hour\n","Generated title: The Good Place: The Bad\n","\n","Plot: Haley meets Arvin’s parents but, when things don’t go as planned, fate leads to an unexpected reunion with all of her ex-boyfriends. Meanwhile, the family seizes on a nursing home visit with Jay’s mean sister, Becky, to settle old scores. But, as Jay, Claire, and Mitchell compete for her time, Phil, Cam, and Gloria end up getting trapped in the home’s basement with no way out.\n","Original title: The Escape\n","Generated title: The Family\n","\n","Plot: Katie and Greg reluctantly agree to let Anna-Kat walk two blocks alone to the library as an 8th birthday present, something they promised her when she was 5. When this gets Katie shunned by other Westport moms for being a bad parent, Oliver's uber-rich friend Cooper, whom Katie dislikes, surprisingly steps up to defend her. Meanwhile, Greg is more worried about Taylor's relationship with boyfriend Eyo, which is starting to get physical.\n","Original title: The Walk\n","Generated title: The One With The Baby\n","\n","Plot: Sophie and Oleg get married, despite some challenges on their wedding day. Disappointing sales at the airport branch of The High put the girls' future there in doubt. The Girls then end up going to Paris using the tickets they got to get into the airport to kidnap Nash. The episode ends with Max and Caroline drinking champagne from their cabin crew friends.\n","Original title: And the Disappointing Unit\n","Generated title: The Wedding Break\n","\n","Plot: When Amy plans a birthday party for Sheldon because he made her birthday so special, he is reluctant on account of a traumatic childhood experience in which his twin sister Missy and her friends lied to him that Batman was coming to their sixth birthday, thereby ruining all his birthdays thereafter. Nonetheless, he relents, and the friends hire TV's Batman, Adam West, to attend as their present. When Sheldon arrives, he is initially happy, but quickly panics and runs into the bathroom. Penny tries to talk to him and they open up to one another. He emerges to apologize to everyone, after which Amy and all assembled share a toast in Sheldon's honor. Sheldon is delighted to hear all the nice things said about him. They then receive a video call from Professor Stephen Hawking, who joins them in singing \"Happy Birthday to You\".\n","Original title: The Celebration Experimentation\n","Generated title: The Night with Jerry\"\n","\n","Plot: The gang celebrates Thanksgiving this year with Lily's estranged father whom she hadn't spoken to in three years. Ted and Robin are given the chance to use Marshall's fourth Slap Bet slap on Barney.\n","Original title: Slapsgiving 2: Revenge of the Slap\n","Generated title: The Three Stars\n","\n","Plot: When Oscar Martinez joins a trivia contest, Andy gets the entire office involved. Eventually, the team made up of Kevin, Erin, Kelly, and Meredith wins. Meanwhile, Dwight goes to Sabre headquarters to petition California to give him a job as a regional manager. California tries to get out of meeting with him, but eventually declines Dwight's request.\n","Original title: Trivia\n","Generated title: The Best Boss\n","\n","Plot: Jim and Pam Halpert are invited to Pam's former fiancé Roy Anderson's wedding. A toast that Roy gives leads Pam and Jim to search their relationships for buried secrets. Meanwhile, Dwight reacts to Nellie's mandatory charity initiative by maintaining that he will donate the money he raises to the Taliban, and Clark hits on Erin Hannon by dangling a fake newscaster job, but Andy takes the bait.\n","Original title: Roy's Wedding\n","Generated title: Buffy & Jeff\n","\n","Plot: As Katie prepares to meet Ashley Clark, a woman she once mentored who then took her job after Katie had children, she can't decide which sweater to buy for the occasion. Her day is shown going two different ways, depending on whether she wears a blue sweater or a pink sweater. Meanwhile, Greg finds that tenure isn't all he hoped it would be, as he deals with a tiny, makeshift office and his annoying new assistant, Grant.\n","Original title: Sliding Sweaters\n","Generated title: My Career\n","\n","Plot: Mitch and Cam's friend Sal announces she's getting married the next day and wants them to be best men, but they can’t help but question whether this party girl can really settle down, and consider an intervention. Gloria has trust issues with the new nanny Dalia. Meanwhile, Gloria and Jay have to deal with Manny's art love for nude females, Claire has a rare bonding moment with Haley, and Phil helps Luke fix a date with a girl named Simone through Facebook.\n","Original title: Best Men\n","Generated title: My Wedding with Cheers\n","\n"]}]},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"CmaSO4dIh3NK"}},{"cell_type":"code","source":["t5_model = AutoModelForSeq2SeqLM.from_pretrained(model_path_t5).to(device)\n","t5_tokenizer = AutoTokenizer.from_pretrained(model_path_t5)"],"metadata":{"id":"DBWf0LPBsvYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def title_generation(input,tokenizer,model,device,beam_search=True):\n","    text_ids = tokenizer([input], max_length=512, return_tensors='pt',padding=True, truncation=True)['input_ids']\n","    \n","    if beam_search:\n","        title_ids = model.generate(\n","        text_ids.to(device), \n","        num_beams=num_beams, \n","        temperature=temperature, \n","        max_length=max_gen_length, \n","        early_stopping=True\n","        )\n","\n","    # The alternative to beam search is Top-K Top-p sampling\n","    if not beam_search:\n","        title_ids = model.generate(\n","            text_ids.to(device), \n","            max_length = max_gen_length,  \n","            no_repeat_ngram_size = no_repeat_ngram_size,\n","            repetition_penalty = repetition_penalty,\n","            top_p = top_p,\n","            temperature = temperature,\n","            do_sample = True,\n","            top_k = top_k,\n","            early_stopping = True\n","        )\n","\n","    title = tokenizer.decode(title_ids[0].tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=False)\n","    return title"],"metadata":{"id":"u9O_FMR3t8XU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_titles = []\n","\n","for plot in test_plots_t5:\n","    title = title_generation(plot,t5_tokenizer,t5_model,device,beam_search=False)\n","    t5_titles.append(title)"],"metadata":{"id":"_VZhDgwyo4aO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(test_plots_t5))\n","print(len(t5_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qD-ctZJD450-","executionInfo":{"status":"ok","timestamp":1686295748697,"user_tz":-120,"elapsed":22,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"3c9fe392-820a-4ef5-c59e-a2f800d0dd29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["228\n","228\n"]}]},{"cell_type":"code","source":["# Printing the first 20 samples\n","for plot, titles in zip(test_plots[:20],zip(test_titles[:20], t5_titles[:20])):\n","    print(f\"Plot: {plot}\")\n","    print(f\"Original title: {titles[0]}\")\n","    print(f\"Generated title: {titles[1]}\")\n","    print() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42YCGIU25CkJ","executionInfo":{"status":"ok","timestamp":1686295748697,"user_tz":-120,"elapsed":19,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"cd31fd43-9c92-4330-88a3-c2b5f3c4de68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Plot: One year after the airing of the documentary, past and present employees of Dunder Mifflin gather for Dwight and Angela's wedding. Dwight initially chooses Jim to be his best man, but Michael Scott shows up and takes his place. Finally, everyone comes together for a final round of interviews, during which Erin reunites with her biological parents and everyone is brought to tears. \n","Original title: Finale\n","Generated title: My Wedding\n","\n","Plot: Dangle (and an unwilling Williams) take time to connect with his black half-brother and half-sister from his father's other family in Chicago.\n","Original title: Back in Black\n","Generated title: The One with a Black Brother and the Other\n","\n","Plot: Dangle's ex-wife's husband proposes to him. A naked Wiegel gets stuck in a giant cake and goes into labor. Dangle holds his wedding at the hospital when Garcia bursts in and declares his love for Dangle's fiancee. Wiegel tells Dangle that she knows who her child's father is.\n","Original title: Dangle's Wedding (Part 1)\n","Generated title: Dangle's Wedding\n","\n","Plot: Mindy is tired of Annette hovering around her relationship with Danny and decides to set her up on a date with Dr. Ledreau, an older practitioner from their building. Jeremy also has his eyes on this soon-to-be-retired doctor, as he is hoping for the practice to receive his patient list. Saddened by his breakup with Tamra, Morgan is convinced by Peter to set up an online dating profile.\n","Original title: How to Lose a Mom in Ten Days\n","Generated title: My New Man\n","\n","Plot: Joey falls for Phoebe's identical twin sister, Ursula, making Phoebe feel neglected. Meanwhile, Chandler finds himself between a rock and a hard place when he has to fire an employee he is attracted to. Ross has doubts about parenthood when he attends Lamaze classes with Carol and Susan. Meanwhile, Monica is unable to fix her TV after Marcel puts it on the \"SAP\" function to Spanish. After weeks of procrastinating, Rachel finally takes down the Christmas lights on their balcony, only to fall off and sprain her ankle.At the hospital, Rachel, who has no health insurance, convinces Monica to trade identities with her so she can use Monica's coverage. The women meet two attractive doctors and arrange a date, requiring them to maintain their switched identities. Ursula dumps Joey without actually telling him, so Phoebe pretends to be her so Joey will finally know. Ross doubts his ability to be a father. After Marcel swallows \"Scrabble\" tiles and has a trip to the hospital, Ross takes care of him, giving him confidence to be a good father.\n","Original title: The One with Two Parts\n","Generated title: A Small Tightrope\n","\n","Plot: When April accidentally scheduled all of Ron's meetings for March 31 thinking that March only had 30 days, Ron has ninety-three meetings scheduled all for one day and enlists the help of everyone in the Parks department to get through them. At one of the meetings, Leslie discovers that Jessica Wicks, former Miss Pawnee and wife of Nick Newport, is planning on making alterations to a Pawnee mansion and she recruits Tom to help her stop it.\n","Original title: 94 Meetings\n","Generated title: The One with Ron's Meetings\n","\n","Plot: A year after Halloween Part III, Jake, Amy and Holt agree on having another heist to prove once and for all who is in fact the true detective/genius in the 99. Holt begins to thwart Jake plans by choosing Charles for his team, while Rosa fully commits to Amy's antics. Meanwhile, Hitchcock and Scully are given the task to watch Terry, as the crew suspects he has something up his sleeve when he refuses to be a part of the heist. Gina proves who the \"Ultimate Human/Genius\" is.\n","Original title: Halloween IV\n","Generated title: The 99\n","\n","Plot: While drunk, Robert shuts down Dunder Mifflin's Binghamton branch. Andy prepares to make his comeback by temporarily forming his own rival paper company. Jim and Dwight work together to defeat a rival Dunder Mifflin salesman who wants the Binghamton branch's clients.\n","Original title: Turf War\n","Generated title: Binghamton\n","\n","Plot: Joey proves to be a sore loser after being nominated for a \"Soapie\" award. When he accepts an award from a different category on behalf of a co-star, he is unwilling to hand it over. However, he later keeps the award anyway when the actress who has won it considers it insignificant. Meanwhile, a male student in Ross’s class angles for a higher test grade by claiming that he loves Ross. Another student reveals that the guy is actually straight, and has used the same ploy on other professors. Ross then gives the student a failing grade, but ends up giving him a \"C\" after some of Ross's colleagues overhear a conversation which sounds like Ross and the student dated.\n","Original title: The One with Joey's Award\n","Generated title: Soapie\n","\n","Plot: Jake's chaotic half-sister, Katie, comes to visit him and Amy for a couple days after a rough break-up. When she considers moving to New York to live with them, the two try to figure out a way to get her to return to Dallas. Terry injures himself after performing yoga with Charles and gets stuck in Hitchcock and Scully’s nap room. Gina tries to set Rosa up on a date.\n","Original title: DFW\n","Generated title: The One with Katie\n","\n","Plot: Oscar arranges a happy hour with the warehouse staff so he can flirt with Matt. Pam is excited to see the staff and brings a date for Michael, but he ends up connecting with the bar manager, Donna, instead. Meanwhile, Andy and Erin announce their relationship. Dwight meets Isabel and drops Angela to hang out with Isabel, making Angela jealous. When Dwight tells Angela to forget about the pre-natal contract, she confronts him in front of Isabel.\n","Original title: Happy Hour\n","Generated title: Happy Hour\n","\n","Plot: Haley meets Arvin’s parents but, when things don’t go as planned, fate leads to an unexpected reunion with all of her ex-boyfriends. Meanwhile, the family seizes on a nursing home visit with Jay’s mean sister, Becky, to settle old scores. But, as Jay, Claire, and Mitchell compete for her time, Phil, Cam, and Gloria end up getting trapped in the home’s basement with no way out.\n","Original title: The Escape\n","Generated title: The One with the Best of Both Worlds\n","\n","Plot: Katie and Greg reluctantly agree to let Anna-Kat walk two blocks alone to the library as an 8th birthday present, something they promised her when she was 5. When this gets Katie shunned by other Westport moms for being a bad parent, Oliver's uber-rich friend Cooper, whom Katie dislikes, surprisingly steps up to defend her. Meanwhile, Greg is more worried about Taylor's relationship with boyfriend Eyo, which is starting to get physical.\n","Original title: The Walk\n","Generated title: The Three Block Walk\n","\n","Plot: Sophie and Oleg get married, despite some challenges on their wedding day. Disappointing sales at the airport branch of The High put the girls' future there in doubt. The Girls then end up going to Paris using the tickets they got to get into the airport to kidnap Nash. The episode ends with Max and Caroline drinking champagne from their cabin crew friends.\n","Original title: And the Disappointing Unit\n","Generated title: The Wedding\n","\n","Plot: When Amy plans a birthday party for Sheldon because he made her birthday so special, he is reluctant on account of a traumatic childhood experience in which his twin sister Missy and her friends lied to him that Batman was coming to their sixth birthday, thereby ruining all his birthdays thereafter. Nonetheless, he relents, and the friends hire TV's Batman, Adam West, to attend as their present. When Sheldon arrives, he is initially happy, but quickly panics and runs into the bathroom. Penny tries to talk to him and they open up to one another. He emerges to apologize to everyone, after which Amy and all assembled share a toast in Sheldon's honor. Sheldon is delighted to hear all the nice things said about him. They then receive a video call from Professor Stephen Hawking, who joins them in singing \"Happy Birthday to You\".\n","Original title: The Celebration Experimentation\n","Generated title: The Birthday Party\n","\n","Plot: The gang celebrates Thanksgiving this year with Lily's estranged father whom she hadn't spoken to in three years. Ted and Robin are given the chance to use Marshall's fourth Slap Bet slap on Barney.\n","Original title: Slapsgiving 2: Revenge of the Slap\n","Generated title: Thanksgiving\n","\n","Plot: When Oscar Martinez joins a trivia contest, Andy gets the entire office involved. Eventually, the team made up of Kevin, Erin, Kelly, and Meredith wins. Meanwhile, Dwight goes to Sabre headquarters to petition California to give him a job as a regional manager. California tries to get out of meeting with him, but eventually declines Dwight's request.\n","Original title: Trivia\n","Generated title: The Trivia Contest\n","\n","Plot: Jim and Pam Halpert are invited to Pam's former fiancé Roy Anderson's wedding. A toast that Roy gives leads Pam and Jim to search their relationships for buried secrets. Meanwhile, Dwight reacts to Nellie's mandatory charity initiative by maintaining that he will donate the money he raises to the Taliban, and Clark hits on Erin Hannon by dangling a fake newscaster job, but Andy takes the bait.\n","Original title: Roy's Wedding\n","Generated title: The Toast\n","\n","Plot: As Katie prepares to meet Ashley Clark, a woman she once mentored who then took her job after Katie had children, she can't decide which sweater to buy for the occasion. Her day is shown going two different ways, depending on whether she wears a blue sweater or a pink sweater. Meanwhile, Greg finds that tenure isn't all he hoped it would be, as he deals with a tiny, makeshift office and his annoying new assistant, Grant.\n","Original title: Sliding Sweaters\n","Generated title: The Sweater\n","\n","Plot: Mitch and Cam's friend Sal announces she's getting married the next day and wants them to be best men, but they can’t help but question whether this party girl can really settle down, and consider an intervention. Gloria has trust issues with the new nanny Dalia. Meanwhile, Gloria and Jay have to deal with Manny's art love for nude females, Claire has a rare bonding moment with Haley, and Phil helps Luke fix a date with a girl named Simone through Facebook.\n","Original title: Best Men\n","Generated title: My Big Day\n","\n"]}]},{"cell_type":"markdown","source":["# Metrics"],"metadata":{"id":"tJwMIeajMQWO"}},{"cell_type":"markdown","source":["Since the generated title won't be the same as the original one, maybe it's more convenient to use metrics which work in semantics rather than metrics which take into account the words but not the meanings behind them nor the context e.g. ROUGE. The generated title can be compared with the actual title from the point of view of context and catchiness, and with the plot from the point of view of context. Following this, there are the metrics which evaluate the two models looking at these considerations."],"metadata":{"id":"0V0BiMU2iWen"}},{"cell_type":"markdown","source":["## Catchiness score"],"metadata":{"id":"86HyuZFwW2Gf"}},{"cell_type":"markdown","source":["From the paper [TiZen: Neural Title Generation for Scientific Papers](https://harshiljain.in/pdf/TiZen_Paper.pdf) I have taken the metric to measure the catchiness of generated titles. Here in the paper, the authors affirm \"*the basic intuition behind the definition of catchiness is that less\n","frequent or rare content words make a title catchy*\" and thus the following formulae are from:\n","> $TC_G=-\\frac{\\sum_{i=1}^m \\textbf{plot_count}[actual[i]]}{m}$\n","\n","> $TC_P=-\\frac{\\sum_{i=1}^n \\textbf{plot_count}[predicted[i]]}{n}$\n","\n","> $CS=TC_G-TC_P$\n","\n","where $\\textbf{plot_count}$ contains the counts of words\n","in the given plot, $\\textbf{actual[i]}$ represents the\n","i-th word in the actual title whereas the $\\textbf{predicted[i]}$ represents\n","the i-th word in the generated title, $\\textbf{m}$ is the number of words\n","in the actual title and $\\textbf{n}$ is the number of words in the generated title, $TC_G$ is the Title Catchiness Score of the actual title, $TC_P$ is the Title Catchiness Score of generated title, $CS$ is the Catchiness Score. "],"metadata":{"id":"jbiHmeqRW5tg"}},{"cell_type":"code","source":["stopwords = [' ', '.', '-', '7', '5', ',', \"'\", ';', '\\n', '\"', '(',')', ':', '—',\n","           '&', '–', '$', '#', '’', '/', '?', '“', '”', '!', '[', ']', '−', '+',\n","           '_', '%', '|', '=', '}', '̈', '́', '̀', '̃', '…']\n","\n","def title_catchiness(plot_count, title):\n","  title_words = [w.lower() for w in title.split(\" \")]\n","  # Length of the title\n","  n=0 \n","  for w in title_words:\n","    if w not in stopwords:\n","      n+=1\n","  \n","  # Sum over the title words\n","  s = 0\n","  for w in title_words:\n","    if w not in stopwords:\n","      if w in plot_count.keys():\n","        s-=plot_count[w]\n","      else:\n","        # If the title word is not present in the plot, set its value to -10\n","        s-=10\n","\n","  tc = s/n\n","  return tc\n","\n","def catchiness_score(plot,original_title,generated_title):\n","  plot_words = [w.lower() for w in plot.split(\" \")]\n","  plot_count = {}\n","  for w in plot_words:\n","    if w not in stopwords:\n","      if w in plot_count.keys():\n","        plot_count[w] += 1\n","      else:\n","        plot_count[w] = 1\n","  tc_g = title_catchiness(plot_count,original_title)\n","  tc_p = title_catchiness(plot_count,generated_title)\n","  return tc_g,tc_p\n","  "],"metadata":{"id":"VGg3uezp-xyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt_catchiness = 0\n","\n","for p,ot,gt in zip(test_plots,test_titles,gpt_titles):\n","  tc_g,tc_p = catchiness_score(p,ot,gt)\n","  cs = tc_g-tc_p\n","  gpt_catchiness+=cs"],"metadata":{"id":"RHr7J6n4Djxx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_catchiness = 0\n","\n","for p,ot,gt in zip(test_plots,test_titles,t5_titles):\n","  tc_g,tc_p = catchiness_score(p,ot,gt)\n","  cs = tc_g-tc_p\n","  t5_catchiness+=cs"],"metadata":{"id":"Cpdqo9qOxHnF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"The average catchiness score for GPT-2 is {gpt_catchiness/len(gpt_titles)}\")\n","print(f\"The average catchiness score for T5 is {t5_catchiness/len(t5_titles)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3vaaYbqxbuh","executionInfo":{"status":"ok","timestamp":1686295762209,"user_tz":-120,"elapsed":10,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"0a94bb83-1115-4ef7-afa3-28341f65b2c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The average catchiness score for GPT-2 is 0.4921313700918962\n","The average catchiness score for T5 is -1.6447211779448612\n"]}]},{"cell_type":"markdown","source":["## Cosine similarity"],"metadata":{"id":"aND-ojt7sXPT"}},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"GUsvREhWEbPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! wget -P /content/ http://nlp.stanford.edu/data/glove.6B.zip\n","! unzip /content/glove.6B.zip\n","! rm glove.6B.zip glove.6B.50d.txt glove.6B.100d.txt glove.6B.200d.txt  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moc6R2oQHPPq","executionInfo":{"status":"ok","timestamp":1686295949027,"user_tz":-120,"elapsed":186825,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"16aca87c-d458-4da2-9509-61d1782fba46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-09 07:29:23--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2023-06-09 07:29:23--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2023-06-09 07:29:24--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘/content/glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  4.99MB/s    in 2m 40s  \n","\n","2023-06-09 07:32:05 (5.12 MB/s) - ‘/content/glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  /content/glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"]}]},{"cell_type":"code","source":["# Load the GloVe word embeddings\n","def load_glove_embeddings(file_path):\n","    embeddings = {}\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            embedding = np.array(values[1:], dtype=np.float32)\n","            embeddings[word] = embedding\n","    return embeddings\n","\n","# Preprocess sentence by tokenizing and normalizing\n","def preprocess_sentence(sentence):\n","    tokens = word_tokenize(sentence.lower())\n","    return tokens"],"metadata":{"id":"gyl2yd2WIX5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove_embeddings = load_glove_embeddings('/content/glove.6B.300d.txt')"],"metadata":{"id":"OkvEm7JENweM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_embeddings(sentence1, sentence2, embeddings):\n","  tokens1 = preprocess_sentence(sentence1)\n","  tokens2 = preprocess_sentence(sentence2)\n","  embeddings1 = [embeddings[token] for token in tokens1 if token in embeddings]\n","  embeddings2 = [embeddings[token] for token in tokens2 if token in embeddings]\n","  return embeddings1,embeddings2"],"metadata":{"id":"veMVrlKymWnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cos_similarity(embeddings1, embeddings2):\n","    if not embeddings1 or not embeddings2:\n","        # If any of the sentences does not have word embeddings, return a similarity score of 0\n","        return 0.0\n","    \n","    # Calculate cosine similarity between embeddings and compute the mean vector\n","    \n","    similarity = cosine_similarity(embeddings1, embeddings2).mean()\n","    return similarity"],"metadata":{"id":"d6pX4Nl_qYkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt_plot_title = 0\n","\n","for p,gt in zip(test_plots,gpt_titles):\n","  embeddings1,embeddings2 = compute_embeddings(gt, p, glove_embeddings)\n","  similarity = cos_similarity(embeddings1, embeddings2)\n","  gpt_plot_title+=similarity"],"metadata":{"id":"B-yvZziK_CMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_plot_title = 0\n","\n","for p,gt in zip(test_plots,t5_titles):\n","  embeddings1,embeddings2 = compute_embeddings(gt, p, glove_embeddings)\n","  similarity = cos_similarity(embeddings1, embeddings2)\n","  t5_plot_title+=similarity"],"metadata":{"id":"3C-OuMMQBVUf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt_title_title = 0\n","\n","for ot,gt in zip(test_titles,gpt_titles):\n","  embeddings1,embeddings2 = compute_embeddings(ot, gt, glove_embeddings)\n","  similarity = cos_similarity(embeddings1, embeddings2)\n","  gpt_title_title+=similarity"],"metadata":{"id":"2v_j6dtJ_v8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_title_title = 0\n","\n","for ot,gt in zip(test_titles,t5_titles):\n","  embeddings1,embeddings2 = compute_embeddings(ot, gt, glove_embeddings)\n","  similarity = cos_similarity(embeddings1, embeddings2)\n","  t5_title_title+=similarity"],"metadata":{"id":"pgzMfdyLBeb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"The average cosine similarity between plots and titles for GPT-2 is {gpt_plot_title/len(gpt_titles)}\")\n","print(f\"The average cosine similarity between plots and titles T5 is {t5_plot_title/len(t5_titles)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1EgBnUV_Hne","executionInfo":{"status":"ok","timestamp":1686295976851,"user_tz":-120,"elapsed":23,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"3e699297-c875-4ee4-d1d7-abb9f907b491"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The average cosine similarity between plots and titles for GPT-2 is 0.27216831143749387\n","The average cosine similarity between plots and titles T5 is 0.2391716864638096\n"]}]},{"cell_type":"code","source":["print(f\"The average cosine similarity between titles and titles for GPT-2 is {gpt_title_title/len(gpt_titles)}\")\n","print(f\"The average cosine similarity between titles and titles for T5 is {t5_title_title/len(t5_titles)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o98EPf5FBsLc","executionInfo":{"status":"ok","timestamp":1686295976852,"user_tz":-120,"elapsed":19,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"38e78ae6-a8c4-4e9e-d8e2-c00883d615c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The average cosine similarity between titles and titles for GPT-2 is 0.23295577256654373\n","The average cosine similarity between titles and titles for T5 is 0.22968915605145557\n"]}]},{"cell_type":"markdown","source":["### Cosine similarity between plots and original titles"],"metadata":{"id":"5vTI0Fy6NsOX"}},{"cell_type":"code","source":["cs_plot_title = 0\n","\n","for p,ot in zip(test_plots,test_titles):\n","  embeddings1,embeddings2 = compute_embeddings(ot, p, glove_embeddings)\n","  similarity = cos_similarity(embeddings1, embeddings2)\n","  cs_plot_title+=similarity"],"metadata":{"id":"mNifVYERNyUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"The average cosine similarity between plots and original titles is {cs_plot_title/len(test_titles)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KuA1kfnMN_0Q","executionInfo":{"status":"ok","timestamp":1686296019545,"user_tz":-120,"elapsed":400,"user":{"displayName":"Federica Cocci","userId":"04786403723953599093"}},"outputId":"5cb668e5-ae8a-438e-a93a-7e55309d6eb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The average cosine similarity between plots and original titles is 0.2160811990360615\n"]}]}]}